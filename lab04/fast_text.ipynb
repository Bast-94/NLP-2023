{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [FastText library](https://fasttext.cc/docs/en/support.html) to train and test a classifier.\n",
    "\n",
    "Go through the following steps.\n",
    "1. (2 points) Turn the dataset into a dataset compatible with Fastext (see the _Tips on using FastText_ section a bit lower).\n",
    "   * For pretreatment, only apply lower casing and punctuation removal.\n",
    "2. (2 points) Train a FastText classifier with default parameters on the training data, and evaluate it on the test data using accuracy.\n",
    "3. (2 points) Use the [hyperparameters search functionality](https://fasttext.cc/docs/en/autotune.html) of FastText and repeat step 2.\n",
    "   * To do so, you'll need to [split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) your training set into a training and a validation set.\n",
    "   * Let the model search for 5 minutes (it's the default search time).\n",
    "   * Don't forget to shuffle (and stratify) your splits. The dataset has its entry ordered by label (0s first, then 1s). Feeding the classifier one class and then the second can mess with its performances.\n",
    "4. (1 points) Look at the differences between the default model and the attributes found with hyperparameters search. How do the two models differ?\n",
    "   * Only refer to the attributes you think are interesting.\n",
    "   * See the _Tips on using FastText_ (just below) for help.\n",
    "5. (1 point) Using the tuned model, take at least 2 wrongly classified examples from the test set, and try explaining why the model failed.\n",
    "6. (Bonus point) Why is it likely that the attributes `minn` and `maxn` are at 0 after an hyperparameter search on our data?\n",
    "   * Hint: on what language are we working?\n",
    "\n",
    "### Tips on using FastText\n",
    "\n",
    "FastText is not exactly documented in details, so you might run into a few problems. The following tips can be useful.\n",
    "\n",
    "#### Training file format\n",
    "\n",
    "Training a FastText classifier takes a text file as input. Every line corresponds to a sample and must have the following format\n",
    "```\n",
    "__label__<your_label> <corresponding text>\n",
    "```\n",
    "For example, in our case a line should look like this.\n",
    "```\n",
    "__label__positive you know robin williams god bless him is constantly...\n",
    "```\n",
    "Also, the data are presented `positive` first and then `negative`. To avoid having a strong model bias toward `negative`, **shuffle your data before training**.\n",
    "\n",
    "#### Attributes\n",
    "\n",
    "You can check a model's attributes as they are listed on the [cheatsheet](https://fasttext.cc/docs/en/options.html). Also, if you have a well configure IDE or use Jupyter Lab, tab is your friend.\n",
    "\n",
    "#### Random seed\n",
    "\n",
    "To my knowledge, there is no way to set the random seed for FastText. It uses C++ code in the back, so using `random.seed()` won't help. For every other model you will use in these projects, please set the random seed to make your results reproductible.\n",
    "\n",
    "#### Data split\n",
    "\n",
    "Do not use the test set for hyperparameters search. Extract a validation set from the training data for that purpose. The test set is only made for comparing final models (see [data leakage](https://en.wikipedia.org/wiki/Leakage_%28machine_learning%29))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddcc8e3c7d24b3d88c1cfd62d3c9a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('imdb')\n",
    "train_df = dataset['train'].to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset convertion to the FastText format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
