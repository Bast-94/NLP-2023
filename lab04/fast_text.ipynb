{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [FastText library](https://fasttext.cc/docs/en/support.html) to train and test a classifier.\n",
    "\n",
    "Go through the following steps.\n",
    "1. (2 points) Turn the dataset into a dataset compatible with Fastext (see the _Tips on using FastText_ section a bit lower).\n",
    "   * For pretreatment, only apply lower casing and punctuation removal.\n",
    "2. (2 points) Train a FastText classifier with default parameters on the training data, and evaluate it on the test data using accuracy.\n",
    "3. (2 points) Use the [hyperparameters search functionality](https://fasttext.cc/docs/en/autotune.html) of FastText and repeat step 2.\n",
    "   * To do so, you'll need to [split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) your training set into a training and a validation set.\n",
    "   * Let the model search for 5 minutes (it's the default search time).\n",
    "   * Don't forget to shuffle (and stratify) your splits. The dataset has its entry ordered by label (0s first, then 1s). Feeding the classifier one class and then the second can mess with its performances.\n",
    "4. (1 points) Look at the differences between the default model and the attributes found with hyperparameters search. How do the two models differ?\n",
    "   * Only refer to the attributes you think are interesting.\n",
    "   * See the _Tips on using FastText_ (just below) for help.\n",
    "5. (1 point) Using the tuned model, take at least 2 wrongly classified examples from the test set, and try explaining why the model failed.\n",
    "6. (Bonus point) Why is it likely that the attributes `minn` and `maxn` are at 0 after an hyperparameter search on our data?\n",
    "   * Hint: on what language are we working?\n",
    "\n",
    "### Tips on using FastText\n",
    "\n",
    "FastText is not exactly documented in details, so you might run into a few problems. The following tips can be useful.\n",
    "\n",
    "#### Training file format\n",
    "\n",
    "Training a FastText classifier takes a text file as input. Every line corresponds to a sample and must have the following format\n",
    "```\n",
    "__label__<your_label> <corresponding text>\n",
    "```\n",
    "For example, in our case a line should look like this.\n",
    "```\n",
    "__label__positive you know robin williams god bless him is constantly...\n",
    "```\n",
    "Also, the data are presented `positive` first and then `negative`. To avoid having a strong model bias toward `negative`, **shuffle your data before training**.\n",
    "\n",
    "#### Attributes\n",
    "\n",
    "You can check a model's attributes as they are listed on the [cheatsheet](https://fasttext.cc/docs/en/options.html). Also, if you have a well configure IDE or use Jupyter Lab, tab is your friend.\n",
    "\n",
    "#### Random seed\n",
    "\n",
    "To my knowledge, there is no way to set the random seed for FastText. It uses C++ code in the back, so using `random.seed()` won't help. For every other model you will use in these projects, please set the random seed to make your results reproductible.\n",
    "\n",
    "#### Data split\n",
    "\n",
    "Do not use the test set for hyperparameters search. Extract a validation set from the training data for that purpose. The test set is only made for comparing final models (see [data leakage](https://en.wikipedia.org/wiki/Leakage_%28machine_learning%29))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "from scripts.sentiment_analysis import fast_text_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Load dataset as a `Pandas` dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47afe683e5884156bd78fc8c933cb855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('imdb')\n",
    "df: pd.DataFrame = dataset['train'].to_pandas()\n",
    "\n",
    "# Display the first 5 rows of the training dataset\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset conversion to the FastText format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__negative i rented i am curiousyellow ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__negative i am curious yellow is a ris...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__negative if only to avoid making this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__negative this film was probably inspi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__negative oh brotherafter hearing abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  __label__negative i rented i am curiousyellow ...      0\n",
       "1  __label__negative i am curious yellow is a ris...      0\n",
       "2  __label__negative if only to avoid making this...      0\n",
       "3  __label__negative this film was probably inspi...      0\n",
       "4  __label__negative oh brotherafter hearing abou...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply pretreatment to the text\n",
    "df['text'] = df['text'].apply(fast_text_utils.preprocess_text)\n",
    "\n",
    "# Convert the data to FastText format\n",
    "fast_text_utils.to_fast_text_format(df=df, label_column_name='label', texts_column_name='text')\n",
    "\n",
    "# Keep only the text column\n",
    "# train_df = train_df[['text']]\n",
    "\n",
    "# Display some rows of the newly formatted data\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train, validation and test sets with `scikit-learn`. Also, we set a high random state to shuffle the datasets well enough in order to keep consistant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df[['text']], test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PATH = './output/train.txt'\n",
    "VALIDATION_PATH = './output/val.txt'\n",
    "TEST_PATH = './output/test.txt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the different datasets to their respective paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "\n",
    "# Write the data to the output files\n",
    "fast_text_utils.save_to_file(df=train_df, file_name=TRAINING_PATH)\n",
    "fast_text_utils.save_to_file(df=val_df, file_name=VALIDATION_PATH)\n",
    "fast_text_utils.save_to_file(df=test_df, file_name=TEST_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `FastText` classifier with the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  95575\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 2853587 lr:  0.000000 avg.loss:  0.457615 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "ft_classifier_default = fasttext.train_supervised(TRAINING_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the classifier on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 5000\n",
      "Precision: 85.30%\n",
      "Recall: 0.853\n"
     ]
    }
   ],
   "source": [
    "results = ft_classifier_default.test(TEST_PATH)\n",
    "fast_text_utils.display_results(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new `FastText` classifier, feeding it with the validation dataset this time. We also specify the training duration (5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:   20 Best score:  0.894750 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 3M words\n",
      "Number of words:  95575\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1176867 lr:  0.000000 avg.loss:  0.026151 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "ft_classifier_tuned = fasttext.train_supervised(input=TRAINING_PATH, autotuneValidationFile=VALIDATION_PATH, autotuneDuration=5 * 60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the newly autotuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 5000\n",
      "Precision: 89.32%\n",
      "Recall: 0.8932\n"
     ]
    }
   ],
   "source": [
    "results = ft_classifier_tuned.test(TEST_PATH)\n",
    "fast_text_utils.display_results(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a precision and recall of ~4% higher on the `tuned` model than the `default` model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Default model attributes -- \n",
      "dim: 100\n",
      "ws: 5\n",
      "epoch: 5\n",
      "lr: 0.1\n",
      "wordNgrams: 1\n",
      "loss: loss_name.softmax\n",
      "lrUpdateRate: 100\n",
      "bucket: 0\n",
      "\n",
      "-- Tuned model attributes --\n",
      "dim: 32\n",
      "ws: 5\n",
      "epoch: 100\n",
      "lr: 5.0\n",
      "wordNgrams: 3\n",
      "loss: loss_name.softmax\n",
      "lrUpdateRate: 100\n",
      "bucket: 266921\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Define a selection of relevant hyperparameters to observe\n",
    "attributes_list: list[str] = ['dim', 'ws', 'epoch', 'lr', 'wordNgrams', 'loss', 'lrUpdateRate', 'bucket']\n",
    "\n",
    "# Display the default model attributes\n",
    "print('-- Default model attributes -- ')\n",
    "fast_text_utils.display_model_attributes(model=ft_classifier_default, parameters=attributes_list)\n",
    "\n",
    "print()\n",
    "\n",
    "# Display the tuned model attributes\n",
    "print('-- Tuned model attributes --')\n",
    "fast_text_utils.display_model_attributes(model=ft_classifier_tuned, parameters=attributes_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we can observe that the context window, the loss, the learning rate update rate, are constant between the two models.\n",
    "\n",
    "Then, we can compare the hyperparameters differences of the two models exhaustively:\n",
    "* `dim` (size of word vectors) - The tuning reduced the dimensionality of the vectors almost by a 10 factor (100 vs 14). We can assume that the model input is less complex and thus less prone to overfitting.\n",
    "\n",
    "* `epoch` (number of epochs) - Here again, the number epochs (iterations) much higher in the default model (5 vs 32). Logically, the more the model is trained, the more the accuracy should increase. However, the model is more prone to overfitting, but the tuning process helped to reduce this effect by selecting the best hyperparameter value.\n",
    "\n",
    "* `lr` (learning rate) - The tuning process almost doubled the learning rate (0.1 vs ~0.2). This goes in the same direction as the previous point, as the learning rate should (generally) vary in regard to the number of epochs. This proves that the default model was undertrained.\n",
    "\n",
    "* `wordNgrams` (max length of word ngram) - The word ngrams increased from 1 to 2. We can assume that this choice was made to prevent the model from overfitting, as the model is now able to take into account the context of the word. Therefore, the model specializes less on the training data and is more generalizable.\n",
    "\n",
    "* `bucket` (number of buckets) - Comparing the number of buckets in the two models (0 vs 6031995), we can make the hypothesis that using a certain amount of buckets is more efficient than using none. As the model takes into account the context of a word, the number of buckets becomes This is probably due to the fact that the model is now able to take into account the context of the word, and thus the number of buckets is more relevant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  __label__negative closer to reality and containing more depth than breakdance stan lathans beat street is still a pretty dull show again this pic is really only cashing in on the breakin craze but at least we get a little bit of entertainment from the plot which concerns the lives of three young friends and a younger brother all growing up in queens new york each has their own unique talent one is a hustler one a dj another an artist who creates burners while little bro lee is a hot hip hop dancerbr br lathan is unable to generate any real audience interest in the story though and his young cast are likewise struggling with their characters therefore it is left almost entirely to the funky music and the fresh dancing to save the daybr br choreography is again sharp for both club and street scenes but this alone is not enough to lift beat street to greater heights unfortunately the film really falls flat late on after showing a glimmer of hope that it just might get interestingbr br sunday august 25 1996  video\n",
      "Prediction:  (('__label__positive',), array([0.99921554]))\n",
      "Ground truth:  __label__negative\n",
      "Example:  __label__negative slow and riddled with inaccuracy overlooking its flaws this is still an interesting account of the famed and heroic siege of the alamo during the texas fight for independence from mexico james arness as jim bowie brian keith as davy crockett alec baldwin as col travis raul julia as general santa anna this madefortv project also stars david ogden stiers kathleen york and jim metzler very good original music by peter bernstein\n",
      "Prediction:  (('__label__positive',), array([1.00001001]))\n",
      "Ground truth:  __label__negative\n"
     ]
    }
   ],
   "source": [
    "examples: list[tuple] = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    example = df['text'].iloc[i]\n",
    "    ground_truth = '__label__' + ('positive' if df['label'].iloc[i] else 'negative')\n",
    "    prediction = ft_classifier_tuned.predict(example)\n",
    "\n",
    "    if prediction[0][0] != ground_truth:\n",
    "        examples.append((example, prediction, ground_truth))\n",
    "    \n",
    "    if len(examples) == 2:\n",
    "        break\n",
    "\n",
    "for example in examples:\n",
    "    print('Example: ', example[0])\n",
    "    print('Prediction: ', example[1])\n",
    "    print('Ground truth: ', example[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus question\n",
    "\n",
    "### Why is it likely that the attributes minn and maxn are at 0 after a hyperparameter search on our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Default model attributes -- \n",
      "minn: 0\n",
      "maxn: 0\n",
      "-- Tuned model attributes --\n",
      "minn: 3\n",
      "maxn: 6\n"
     ]
    }
   ],
   "source": [
    "parameters: list[str] = ['minn', 'maxn']\n",
    "\n",
    "# Display the default model attributes\n",
    "print('-- Default model attributes -- ')\n",
    "fast_text_utils.display_model_attributes(model=ft_classifier_default, parameters=parameters)\n",
    "# Display the tuned model attributes\n",
    "print('-- Tuned model attributes --')\n",
    "fast_text_utils.display_model_attributes(model=ft_classifier_tuned, parameters=parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are here processing English texts. Thus, as we want to take the context of a word into consideration, we would rather use the `wordNgrams` hyperparameter. The `minn` and `maxn` hyperparameters are used to caption characters contexts, which is not very relevant in the case of English."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
