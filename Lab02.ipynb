{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import datasets as ds\n",
    "from collections import Counter\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "How many splits does the dataset has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test', 'unsupervised']\n",
      "Number of splits: 3\n"
     ]
    }
   ],
   "source": [
    "splits: list[str] = ds.get_dataset_split_names('imdb')\n",
    "print(splits)\n",
    "print(f'Number of splits: {len(splits)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 splits in the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "How big are these splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split size : 25000\n",
      "test split size : 25000\n",
      "unsupervised split size : 50000\n"
     ]
    }
   ],
   "source": [
    "def load_datasets() -> list[ds.Dataset]:\n",
    "    \"\"\"\n",
    "    Loads the IMDB dataset from the datasets library.\n",
    "    Returns:\n",
    "        datasets: list[ds.Dataset] - List of datasets\n",
    "    \"\"\"\n",
    "    datasets: list[ds.Dataset] = []\n",
    "    for split in splits:\n",
    "        dataset: ds.Dataset = ds.load_dataset('imdb', split=split)\n",
    "        datasets.append(dataset)\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "datasets: list[ds.Dataset] = load_datasets()\n",
    "for i, dataset in enumerate(datasets):\n",
    "    print(f'{splits[i]} split size : {dataset.num_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "What is the proportion of each class on the supervised splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Class 0\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "Class 1\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "test\n",
      "Class 0\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "Class 1\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get only supervised datasets\n",
    "supervised_datasets: list[pd.DataFrame] = list(map(lambda x: x.to_pandas(), datasets[0:2]))\n",
    "\n",
    "# For each dataset, print the number of samples for each class\n",
    "for i, dataset in enumerate(supervised_datasets):\n",
    "    data_frame = dataset\n",
    "    print(splits[i])\n",
    "    print('Class 0')\n",
    "    print(data_frame.where(data_frame['label'] == 0).count())\n",
    "    print('Class 1')\n",
    "    print(data_frame.where(data_frame['label'] == 1).count())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, each class represents 50% of the supervised dataset (both in train and test samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Create an adapted processing function which lower case the text and replace punctuations with text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(text: str) -> str:\n",
    "  \"\"\"\n",
    "  Removes HTML tags from the given text.\n",
    "  Args:\n",
    "      text (str): Text with html tags.\n",
    "  Returns:\n",
    "      str: Text from all html tags.\n",
    "  \"\"\"\n",
    "  no_html = BeautifulSoup(text).get_text()\n",
    "  return no_html\n",
    "\n",
    "def text_processing(text: str) -> str:\n",
    "  \"\"\"\n",
    "  Pre-processes the given text.\n",
    "  Args:\n",
    "      text (str): Text to process\n",
    "  Returns:\n",
    "      str: Processed text\n",
    "  \"\"\"\n",
    "  result_text = text\n",
    "  result_text = clean_html(result_text)\n",
    "  result_text = result_text.lower()\n",
    "  pattern = r\"(?<![a-zA-Z])[^\\w\\s]|[^\\w\\s](?![a-zA-Z])\"\n",
    "  result_text = re.sub(pattern, \"\", result_text)\n",
    "  result_text = result_text.strip()\n",
    "  return re.sub(\"(\\s+)\", \" \", result_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiny test (preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocessing(input: str, expected: str) -> None:\n",
    "    result: str = text_processing(input)\n",
    "    assert text_processing(input) == expected or print(result)\n",
    "\n",
    "test_preprocessing(\"Hello, ,,,World!::\", \"hello world\")\n",
    "test_preprocessing(\"Hello,        U.S.A!\", \"hello u.s.a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply `text_processing` function on `text` field of our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_data_frame: pd.DataFrame = supervised_datasets[0]\n",
    "train_data_frame.text = train_data_frame.text.apply(text_processing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize function\n",
    "Function to cut processed text into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str)-> list:\n",
    "    \"\"\"\n",
    "    Tokenizes the given text.\n",
    "    Args:\n",
    "        text (str): Text to tokenize (pre-processed)\n",
    "    Returns:\n",
    "        list: List of tokens\n",
    "    \"\"\"\n",
    "    return [w for w in re.split(\"\\W+\", text)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe for vocabulary\n",
    "This function compute the vocabulary dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(texts_serie: pd.Series) -> Counter:\n",
    "    \"\"\"\n",
    "    Builds the vocabulary of the given texts serie.\n",
    "    Args:\n",
    "        text_serie (pd.Series): Text serie\n",
    "    Returns:\n",
    "        Counter: Vocabulary\n",
    "    \"\"\"\n",
    "    vocabulary: Counter = None # Use Counter as a dictionary with word occurrences\n",
    "    for text in texts_serie:\n",
    "        word_list: list[str] = tokenize(text=text)\n",
    "        if vocabulary is None:\n",
    "            vocabulary = Counter(word_list)\n",
    "        else:\n",
    "            vocabulary.update(word_list)\n",
    "    return vocabulary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the vocabulary and change the label type of the train data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary: Counter = build_vocabulary(texts_serie=train_data_frame.text)\n",
    "train_data_frame.label = train_data_frame.label.astype(str)\n",
    "counter_class: pd.DataFrame = train_data_frame.groupby(\"label\").agg({'text': build_vocabulary})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function which returns occurence of a word of a specific class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(counter_class: pd.DataFrame, class_name: str, word: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns the number of occurrences of the given word in the given class.\n",
    "    Args:\n",
    "        counter_class (pd.DataFrame): DataFrame with the vocabulary of each class\n",
    "        class_name (str): Class name / label\n",
    "        word (str): Word\n",
    "    Returns:\n",
    "        int: Number of occurrences of the given word in the given class\n",
    "    \"\"\"\n",
    "    return counter_class.loc[class_name][\"text\"][word]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of naive Bayes classifier\n",
    "\n",
    "Let's implement this pseudo-code:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](nbc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words(vocabulary: Counter, c: str, counter_class: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Returns the total number of words in a class for the given vocabulary.\n",
    "    Args:\n",
    "        vocabulary (Counter): Vocabulary\n",
    "        c (str): Class name / label\n",
    "        counter_class (pd.DataFrame): DataFrame with the vocabulary of each class\n",
    "    Returns:\n",
    "        int: Total number of words in the given class\n",
    "    \"\"\"\n",
    "    total: int = 0\n",
    "    for w in vocabulary:\n",
    "        total += word_count(counter_class, c, w)\n",
    "    return total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function which affect a specified value for loglikelihood dictionnary at index `word,class_value`. It represent the loglikelihood for a word of a specific class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_loglikelihood(loglikelihood: dict, word: str, class_value: str, value_to_affect: float) -> None:\n",
    "    \"\"\"\n",
    "    Fills the loglikelihood dictionary with the given values.\n",
    "    Args:\n",
    "        loglikelihood (dict): Loglikelihood dictionary\n",
    "        word (str): Word\n",
    "        class_value (str): Class name / label\n",
    "        value_to_affect (float): Value to affect\n",
    "    \"\"\"\n",
    "    if (loglikelihood.get(word) is None):\n",
    "        loglikelihood[word] = {}\n",
    "    loglikelihood[word][class_value] = value_to_affect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(train_data_frame: pd.DataFrame, vocabulary: Counter, counter_class: pd.DataFrame) -> tuple[dict, dict, Counter]:\n",
    "    \"\"\"\n",
    "    Builds the Naive Bayes classifier.\n",
    "    Args:\n",
    "        train_data_frame (pd.DataFrame): Training data frame\n",
    "        vocabulary (Counter): Vocabulary\n",
    "        counter_class (pd.DataFrame): DataFrame with the vocabulary of each class\n",
    "    Returns:\n",
    "        tuple[dict, dict, Counter]: Tuple with the logprior, loglikelihood and vocabulary\n",
    "    \"\"\"\n",
    "    total_document_count: int = train_data_frame.text.count()\n",
    "    class_label_set: list = list(train_data_frame.groupby(\"label\").groups.keys())\n",
    "    logprior: dict = {}\n",
    "    loglikelihood: dict = {}\n",
    "    \n",
    "    for current_class in class_label_set:\n",
    "        class_document_count: int = train_data_frame[train_data_frame.label == current_class].text.count()\n",
    "        logprior[current_class] = np.log(class_document_count/total_document_count)\n",
    "        total: int = total_words(vocabulary,current_class,counter_class) + len(vocabulary)\n",
    "        \n",
    "        for word in vocabulary:\n",
    "            count_w_c = word_count(counter_class, current_class, word) + 1\n",
    "            log_like_value = np.log(count_w_c / total)\n",
    "            fill_loglikelihood(loglikelihood,word,current_class,log_like_value)\n",
    "            \n",
    "    return logprior, loglikelihood, vocabulary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Naive Bayes classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the test function of our naive Bayes classifier which apply for one testdoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes_classifier(testdoc: str, logprior: dict, loglikelihood: dict, train_data_frame: pd.DataFrame, vocabulary: Counter) -> tuple:\n",
    "    \"\"\"\n",
    "    Tests the Naive Bayes classifier.\n",
    "    Args:\n",
    "        testdoc (str): Test document\n",
    "        logprior (dict): Logprior\n",
    "        loglikelihood (dict): Loglikelihood\n",
    "        train_data_frame (pd.DataFrame): Training data frame\n",
    "        vocabulary (Counter): Vocabulary\n",
    "    Returns:\n",
    "        tuple: Tuple with the predicted class and the loglikelihood\n",
    "    \"\"\"\n",
    "    class_set: list = list(train_data_frame.groupby(\"label\").groups.keys())\n",
    "    sums: dict = {}\n",
    "    max_class = None\n",
    "\n",
    "    for c in class_set:\n",
    "        sums[c] = logprior[c]\n",
    "        word_list = tokenize(testdoc)\n",
    "        for w in word_list:\n",
    "            if(vocabulary[w] != 0):\n",
    "                sums[c] = sums[c] + loglikelihood[w][c]\n",
    "\n",
    "        if (max_class is None or sums[max_class] < sums[c]):\n",
    "            max_class = c\n",
    "        \n",
    "    return max_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data\n",
    "Make prediction on each text from `test_data_frame` and store them in `model_result`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_frame: pd.DataFrame = supervised_datasets[1]\n",
    "test_data_frame.label = test_data_frame.label.astype(str)\n",
    "logprior, loglikelihood, vocabulary = naive_bayes_classifier(train_data_frame,vocabulary,counter_class)\n",
    "test_data_frame_2: pd.DataFrame = test_data_frame\n",
    "test_nbc_function = lambda text : test_naive_bayes_classifier(text, logprior,loglikelihood,train_data_frame,vocabulary)\n",
    "test_data_frame_2[\"model_result\"] = test_data_frame_2.text.apply(test_nbc_function)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get results\n",
    "We are now able to get the good predictions count, hence we can get an accuracy ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 82.40\n"
     ]
    }
   ],
   "source": [
    "good_predictions_count: int = (test_data_frame_2[test_data_frame_2.label == test_data_frame_2.model_result]).label.count()\n",
    "text_count: int = test_data_frame_2.text.count()\n",
    "accuracy_ratio: float = good_predictions_count / text_count\n",
    "print(f'Test accuracy : {(accuracy_ratio * 100):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
