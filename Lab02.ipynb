{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import datasets as ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "How many splits does the dataset has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test', 'unsupervised']\n",
      "Number of splits: 3\n"
     ]
    }
   ],
   "source": [
    "splits = ds.get_dataset_split_names('imdb')\n",
    "print(splits)\n",
    "print(f'Number of splits: {len(splits)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 splits in the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "How big are these splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/bastien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/home/bastien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/home/bastien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    }
   ],
   "source": [
    "dataset_0 = ds.load_dataset('imdb', split=splits[0])\n",
    "dataset_1 = ds.load_dataset('imdb', split=splits[1])\n",
    "dataset_2 = ds.load_dataset('imdb', split=splits[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split size : 25000\n",
      "test split size : 25000\n",
      "unsupervised split size : 50000\n"
     ]
    }
   ],
   "source": [
    "print(f'{splits[0]} split size : {dataset_0.num_rows}')\n",
    "print(f'{splits[1]} split size : {dataset_1.num_rows}')\n",
    "print(f'{splits[2]} split size : {dataset_2.num_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "What is the proportion of each class on the supervised splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Test\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dataset 0: Train\n",
    "train_data_frame = dataset_0.to_pandas()\n",
    "print(\"Train\")\n",
    "print(train_data_frame.where(train_data_frame['label'] == 0).count())\n",
    "print(train_data_frame.where(train_data_frame['label'] == 1).count())\n",
    "\n",
    "print(\"\\n\")\n",
    "# Dataset 1: Test\n",
    "print(\"Test\")\n",
    "test_data_frame = dataset_1.to_pandas()\n",
    "print(test_data_frame.where(test_data_frame['label'] == 0).count())\n",
    "print(test_data_frame.where(test_data_frame['label'] == 1).count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, each class represents 50% of the supervised dataset (both in train and test samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Create an adapted processing function which lower case the text and replace punctuations with text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html(text: str) -> str:\n",
    "  \"\"\"Function which removes unuseful HTML tags of provided text.\"\"\"\n",
    "  no_html = BeautifulSoup(text).get_text()\n",
    "  return no_html\n",
    "\n",
    "def text_processing(text: str) -> str:\n",
    "  \"\"\"Function which  process provided text, it removes punctuations, unuseful spaces and html tags.\"\"\"\n",
    "  result_text = text\n",
    "  result_text = clean_html(result_text)\n",
    "  result_text = result_text.lower()\n",
    "  pattern = r\"(?<![a-zA-Z])[^\\w\\s]|[^\\w\\s](?![a-zA-Z])\"\n",
    "  result_text = re.sub(pattern, \"\", result_text)\n",
    "  result_text = result_text.strip()\n",
    "  return re.sub(\"(\\s+)\", \" \", result_text)\n",
    "\n",
    "#tiny test\n",
    "result = text_processing(\"Hello,        U.S.A!\")\n",
    "expected = 'hello u.s.a'\n",
    "assert result == expected or print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply `text_processing` function on `text` field of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame.text = train_data_frame.text.apply(text_processing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Vocabulary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize function\n",
    "Function to cut processed text into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str)-> list:\n",
    "    return [w for w in re.split(\"\\W+\", text)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe for vocabulary\n",
    "This function compute the vocabulary dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_vocabulary(train_data_frame: pd.DataFrame) -> Counter:\n",
    "    vocabulary = None\n",
    "    for text in train_data_frame.text:\n",
    "        word_list = tokenize(text=text)\n",
    "        if(vocabulary is None):\n",
    "            vocabulary =Counter(word_list)\n",
    "            continue\n",
    "        vocabulary.update(word_list)\n",
    "    return vocabulary\n",
    "\n",
    "def compute_vocabulary_series(text_serie: pd.Series) -> Counter:\n",
    "    vocabulary = None\n",
    "    for text in text_serie:\n",
    "        word_list = tokenize(text=text)\n",
    "        if(vocabulary is None):\n",
    "            vocabulary =Counter(word_list)\n",
    "            continue\n",
    "        vocabulary.update(word_list)\n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = compute_vocabulary(train_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame.label = train_data_frame.label.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_class = train_data_frame.groupby(\"label\").agg({'text':compute_vocabulary_series})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(counter_class: pd.DataFrame, class_name: str, word: str) -> int:\n",
    "    return counter_class.loc[class_name][\"text\"][word]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Let's implement this pseudo code:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](nbc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3089707"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "c = \"1\"\n",
    "\n",
    "def total_words(vocabulary: Counter, c: str):\n",
    "    total = 0\n",
    "    for w in vocabulary:\n",
    "        total += (word_count(counter_class,c,w)+1)\n",
    "    return total\n",
    "    \n",
    "total_words(vocabulary,\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_loglikelihood(loglikelihood: dict, w: str, c:str, value: float):\n",
    "    if (loglikelihood.get(w) is None):\n",
    "        loglikelihood[w] = {}\n",
    "    loglikelihood[w][c] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(train_data_frame: pd.DataFrame, vocabulary: Counter, counter_class: pd.DataFrame) :\n",
    "    n_doc = train_data_frame.text.count()\n",
    "    class_set = list(train_data_frame.groupby(\"label\").groups.keys())\n",
    "    logprior = {}\n",
    "    loglikelihood ={}\n",
    "    for c in class_set:\n",
    "        n_c = train_data_frame[train_data_frame.label == c].text.count()\n",
    "        print(n_doc)\n",
    "        big_doc = train_data_frame[train_data_frame.label == c].text\n",
    "        logprior[c] = np.log(n_c/n_doc)\n",
    "        counter = 0\n",
    "        total = total_words(vocabulary,c) + len(vocabulary)\n",
    "        for w in vocabulary:\n",
    "            count_w_c = word_count(counter_class, c, w) +1\n",
    "            value = np.log(count_w_c/total)\n",
    "            fill_loglikelihood(loglikelihood,w,c,value)\n",
    "            counter +=1\n",
    "            \n",
    "            \n",
    "    return logprior,loglikelihood   , vocabulary\n",
    "\n",
    "logprior,loglikelihood , vocabulary =naive_bayes_classifier(train_data_frame,vocabulary,counter_class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_naive_bayes_classifier(testdoc :str, logprior:dict, loglikelihood: dict, train_data_frame: pd.DataFrame, vocabulary: Counter) -> tuple:\n",
    "    class_set = list(train_data_frame.groupby(\"label\").groups.keys())\n",
    "    sums = {}\n",
    "    max_class = None\n",
    "    for c in class_set:\n",
    "        sums[c] = logprior[c]\n",
    "        word_list = tokenize(testdoc)\n",
    "        for w in word_list:\n",
    "            if(vocabulary[w] != 0):\n",
    "                sums[c] = sums[c] + loglikelihood[w][c]\n",
    "        if (max_class is None or sums[max_class] < sums[c]):\n",
    "            max_class = c\n",
    "        \n",
    "    return max_class\n",
    "\n",
    "test_data_frame.label = test_data_frame.label.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_naive_bayes_classifier(test_data_frame.text[0], logprior,loglikelihood,train_data_frame,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_frame_2 = test_data_frame\n",
    "apply_function = lambda text : test_naive_bayes_classifier(text, logprior,loglikelihood,train_data_frame,vocabulary)\n",
    "\n",
    "test_data_frame_2[\"model_result\"] = test_data_frame_2.text.apply(apply_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy_ratio*100 = 82.44399999999999\n"
     ]
    }
   ],
   "source": [
    "good_predictions_count = (test_data_frame_2[test_data_frame_2.label == test_data_frame_2.model_result]).label.count()\n",
    "text_count = test_data_frame_2.text.count()\n",
    "accuracy_ratio = good_predictions_count/text_count\n",
    "print(f'{ accuracy_ratio*100 = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
