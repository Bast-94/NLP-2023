{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import datasets as ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "How many splits does the dataset has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test', 'unsupervised']\n",
      "Number of splits: 3\n"
     ]
    }
   ],
   "source": [
    "splits = ds.get_dataset_split_names('imdb')\n",
    "print(splits)\n",
    "print(f'Number of splits: {len(splits)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 splits in the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "How big are these splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/bastien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/home/bastien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/home/bastien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    }
   ],
   "source": [
    "dataset_0 = ds.load_dataset('imdb', split=splits[0])\n",
    "dataset_1 = ds.load_dataset('imdb', split=splits[1])\n",
    "dataset_2 = ds.load_dataset('imdb', split=splits[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split size : 25000\n",
      "test split size : 25000\n",
      "unsupervised split size : 50000\n"
     ]
    }
   ],
   "source": [
    "print(f'{splits[0]} split size : {dataset_0.num_rows}')\n",
    "print(f'{splits[1]} split size : {dataset_1.num_rows}')\n",
    "print(f'{splits[2]} split size : {dataset_2.num_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "What is the proportion of each class on the supervised splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Test\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dataset 0: Train\n",
    "train_data_frame = dataset_0.to_pandas()\n",
    "print(\"Train\")\n",
    "print(train_data_frame.where(train_data_frame['label'] == 0).count())\n",
    "print(train_data_frame.where(train_data_frame['label'] == 1).count())\n",
    "\n",
    "print(\"\\n\")\n",
    "# Dataset 1: Test\n",
    "print(\"Test\")\n",
    "test_data_frame = dataset_1.to_pandas()\n",
    "print(test_data_frame.where(test_data_frame['label'] == 0).count())\n",
    "print(test_data_frame.where(test_data_frame['label'] == 1).count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, each class represents 50% of the supervised dataset (both in train and test samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Create an adapted processing function which lower case the text and replace punctuations with text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html(text: str) -> str:\n",
    "  \"\"\"Function which removes unuseful HTML tags of provided text.\"\"\"\n",
    "  no_html = BeautifulSoup(text).get_text()\n",
    "  return no_html\n",
    "\n",
    "def text_processing(text: str) -> str:\n",
    "  \"\"\"Function which  process provided text, it removes punctuations, unuseful spaces and html tags.\"\"\"\n",
    "  result_text = text\n",
    "  result_text = clean_html(result_text)\n",
    "  result_text = result_text.lower()\n",
    "  pattern = r\"(?<![a-zA-Z])[^\\w\\s]|[^\\w\\s](?![a-zA-Z])\"\n",
    "  result_text = re.sub(pattern, \"\", result_text)\n",
    "  result_text = result_text.strip()\n",
    "  return re.sub(\"(\\s+)\", \" \", result_text)\n",
    "\n",
    "#tiny test\n",
    "result = text_processing(\"Hello,        U.S.A!\")\n",
    "expected = 'hello u.s.a'\n",
    "assert result == expected or print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply `text_processing` function on `text` field of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame.text = train_data_frame.text.apply(text_processing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
