{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import datasets as ds\n",
    "from collections import Counter\n",
    "\n",
    "from scripts import data\n",
    "from scripts.naive_bayes import from_scratch as naive_bayes\n",
    "from scripts.naive_bayes import scikit_learn as sk_naive_bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "How many splits does the dataset has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits:\n",
      "'train'\n",
      "'test'\n",
      "'unsupervised'\n",
      "Number of splits: 3\n"
     ]
    }
   ],
   "source": [
    "splits: list[str] = ds.get_dataset_split_names('imdb')\n",
    "print('Splits:')\n",
    "for split in splits:\n",
    "    print(f'\\'{split}\\'')\n",
    "print(f'Number of splits: {len(splits)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 splits in the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "How big are these splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "'train' split size : 25000\n",
      "'test' split size : 25000\n",
      "'unsupervised' split size : 50000\n"
     ]
    }
   ],
   "source": [
    "datasets: list[ds.Dataset] = data.load_datasets(splits=splits)\n",
    "print('Dataset sizes:')\n",
    "for i, dataset in enumerate(datasets):\n",
    "    print(f'\\'{splits[i]}\\' split size : {dataset.num_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "What is the proportion of each class on the supervised splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised dataset sizes:\n",
      "\n",
      "\n",
      "'train'\n",
      "Class 0\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "Class 1\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "'test'\n",
      "Class 0\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "Class 1\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get only supervised datasets\n",
    "supervised_datasets: list[pd.DataFrame] = data.datasets_to_dataframes(datasets[0:2])\n",
    "\n",
    "print('Supervised dataset sizes:')\n",
    "# For each dataset, print the number of samples for each class\n",
    "for i, dataset in enumerate(supervised_datasets):\n",
    "    print('\\n')\n",
    "    print(f'\\'{splits[i]}\\'')\n",
    "    print('Class 0')\n",
    "    print(dataset.where(dataset['label'] == 0).count())\n",
    "    print('Class 1')\n",
    "    print(dataset.where(dataset['label'] == 1).count())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, each class represents 50% of the supervised dataset (both in train and test samples)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_preprocessing(\"Hello, ,,,World!::\", \"hello world\")\n",
    "data.test_preprocessing(\"Hello,        U.S.A!\", \"hello u.s.a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply the preprocessing to the `text` field of our training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = data.processed_dataframes(supervised_datasets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the vocabulary and change the label type of the train data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary: Counter = naive_bayes.build_vocabulary(texts_serie=train_df.text)\n",
    "train_df.label = train_df.label.astype(str)\n",
    "counter_class: pd.DataFrame = train_df.groupby(\"label\").agg({'text': naive_bayes.build_vocabulary})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier pseudo-code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./nbc.png\" width=\"30%\" height=\"20%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'From scratch' Naive Bayes classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Naive Bayes model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of variables `logprior, loglikelihood` represent the naive bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikelihood = naive_bayes.classifier(train_df, vocabulary, counter_class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions\n",
    "Make prediction on each text of the training and testing sets and store them in a `'model_result'` column in the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping lambda function to apply to each row of the dataframe\n",
    "test_classifier = lambda text : naive_bayes.test_classifier(text, logprior, loglikelihood, train_df, vocabulary)\n",
    "\n",
    "test_df.label = test_df.label.astype(str)\n",
    "\n",
    "train_df[\"model_result\"] = train_df.text.apply(test_classifier)\n",
    "test_df[\"model_result\"] = test_df.text.apply(test_classifier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 ('From scratch' implementation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "We are now able to get the good predictions count, hence we can get an accuracy ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 89.84%\n",
      "Test accuracy: 81.18%\n"
     ]
    }
   ],
   "source": [
    "naive_bayes.display_accuracy(train_df, \"Train\")\n",
    "naive_bayes.display_accuracy(test_df, \"Test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = sk_naive_bayes.pipeline()\n",
    "\n",
    "# Train the model on the training set\n",
    "pipeline.fit(train_df.text, train_df.label)\n",
    "\n",
    "# Make predictions on the train and test sets\n",
    "train_predictions = pipeline.predict(train_df.text)\n",
    "test_predictions = pipeline.predict(test_df.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (scikit-learn implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report (testing):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83     12500\n",
      "           1       0.86      0.76      0.80     12500\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.82      0.82      0.82     25000\n",
      "weighted avg       0.82      0.82      0.82     25000\n",
      "\n",
      "Confusion matrix (testing):\n",
      "[[10969  1531]\n",
      " [ 3051  9449]]\n",
      "\n",
      "\n",
      "Training accuracy: 90.32%\n",
      "Testing accuracy: 81.67%\n"
     ]
    }
   ],
   "source": [
    "# Print the classificiation report\n",
    "print('Classification report (testing):')\n",
    "sk_naive_bayes.print_classification_report(test_df, test_predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('Confusion matrix (testing):')\n",
    "sk_naive_bayes.print_confusion_matrix(test_df, test_predictions)\n",
    "print('\\n')\n",
    "\n",
    "# Print the accuracy score (training)\n",
    "sk_naive_bayes.print_accuracy_score(train_df, train_predictions, 'Training')\n",
    "# Print the accuracy score (testing)\n",
    "sk_naive_bayes.print_accuracy_score(test_df, test_predictions, 'Testing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (FIXME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: A revoir (regarder la doc de CountVectorizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'hyperparamètre $\\alpha$ permet de réguler le sur-apprentissage. En effet, si $\\alpha$ est trop grand, le modèle va être trop régularisé et donc ne pas être capable de prédire correctement les données. Si $\\alpha$ est trop petit, le modèle va être trop adapté aux données d'entrainement et donc ne pas être capable de prédire correctement les données de test. C'est un paramètre que l'on peut ajuster dans l'implémentation `scikit-learn`, mais pas notre propre implémentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy metrics is a sufficient metric to measure the performance of our model. Indeed, the dataset is equally distributed between the classes and are well separated between positive and negative sentiments."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 (TODO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i - Highest likelihood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the words with the highest likelihood in each class (if you use scikit-learn, you want to check feature_log_prob_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  0\n",
      "Most likely words:  ['was', 'that', 'this', 'in', 'it', 'is', 'to', 'of', 'and', 'the']\n",
      "\n",
      "Class:  1\n",
      "Most likely words:  ['as', 'this', 'that', 'it', 'in', 'is', 'to', 'of', 'and', 'the']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the most likely words\n",
    "sk_naive_bayes.print_most_likely_words(pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii - Stopwords removal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/francois.soulier/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 91.91%\n",
      "Testing accuracy: 82.74%\n"
     ]
    }
   ],
   "source": [
    "stop_words: list[str] = data.get_stopwords()\n",
    "pipeline = sk_naive_bayes.pipeline(stop_words=stop_words)\n",
    "\n",
    "# Train the model on the training set\n",
    "pipeline.fit(train_df.text, train_df.label)\n",
    "\n",
    "# Make predictions on the train and test sets\n",
    "train_predictions = pipeline.predict(train_df.text)\n",
    "test_predictions = pipeline.predict(test_df.text)\n",
    "\n",
    "# Print the accuracy score (training)\n",
    "sk_naive_bayes.print_accuracy_score(train_df, train_predictions, 'Training')\n",
    "# Print the accuracy score (testing)\n",
    "sk_naive_bayes.print_accuracy_score(test_df, test_predictions, 'Testing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/francois.soulier/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new preprocessing function is implemented in './scripts/naive_bayes/scikit_learn.py'. The text preprocessing now includes lemmatization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (FIXME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get supervised data and apply preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = data.get_train_test_sets(dataframes=supervised_datasets)\n",
    "\n",
    "train_df.text = train_df.text.apply(data.preprocess_with_lemmatizer)\n",
    "test_df.text = test_df.text.apply(data.preprocess_with_lemmatizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = sk_naive_bayes.pipeline(stop_words=stop_words)\n",
    "\n",
    "# Train the model on the training set\n",
    "pipeline = pipeline.fit(train_df.text, train_df.label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 91.53%\n",
      "Testing accuracy: 82.37%\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the train and test sets\n",
    "train_predictions = pipeline.predict(train_df.text)\n",
    "test_predictions = pipeline.predict(test_df.text)\n",
    "\n",
    "# Print the accuracy score (training)\n",
    "sk_naive_bayes.print_accuracy_score(train_df, train_predictions, 'Training')\n",
    "# Print the accuracy score (testing)\n",
    "sk_naive_bayes.print_accuracy_score(test_df, test_predictions, 'Testing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (TODO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
