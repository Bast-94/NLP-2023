{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import datasets as ds\n",
    "import string\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "How many splits does the dataset has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test', 'unsupervised']\n",
      "Number of splits: 3\n"
     ]
    }
   ],
   "source": [
    "splits: list[str] = ds.get_dataset_split_names('imdb')\n",
    "print(splits)\n",
    "print(f'Number of splits: {len(splits)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 splits in the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "How big are these splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split size : 25000\n",
      "test split size : 25000\n",
      "unsupervised split size : 50000\n"
     ]
    }
   ],
   "source": [
    "def load_datasets() -> list[ds.Dataset]:\n",
    "    \"\"\"\n",
    "    Loads the IMDB dataset from the datasets library.\n",
    "    Returns:\n",
    "        datasets: list[ds.Dataset] - List of datasets\n",
    "    \"\"\"\n",
    "    datasets: list[ds.Dataset] = []\n",
    "    for split in splits:\n",
    "        dataset: ds.Dataset = ds.load_dataset('imdb', split=split)\n",
    "        datasets.append(dataset)\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "datasets: list[ds.Dataset] = load_datasets()\n",
    "for i, dataset in enumerate(datasets):\n",
    "    print(f'{splits[i]} split size : {dataset.num_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "What is the proportion of each class on the supervised splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Class 0\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "Class 1\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "test\n",
      "Class 0\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "Class 1\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "supervised_datasets: list[ds.Dataset] = datasets[0:2]\n",
    "\n",
    "for i, dataset in enumerate(supervised_datasets):\n",
    "    train_data_frame = dataset.to_pandas()\n",
    "    print(splits[i])\n",
    "    print('Class 0')\n",
    "    print(train_data_frame.where(train_data_frame['label'] == 0).count())\n",
    "    print('Class 1')\n",
    "    print(train_data_frame.where(train_data_frame['label'] == 1).count())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, each class represents 50% of the supervised dataset (both in train and test samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Create an adapted processing function which lower case the text and replace punctuations with text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(text: str) -> str:\n",
    "  \"\"\"\n",
    "  Removes HTML tags from the given text.\n",
    "  Args:\n",
    "      text (str): Text with html tags.\n",
    "  Returns:\n",
    "      str: Text from all html tags.\n",
    "  \"\"\"\n",
    "  no_html = BeautifulSoup(text).get_text()\n",
    "  return no_html\n",
    "\n",
    "def text_processing(text: str) -> str:\n",
    "  \"\"\"\n",
    "  Pre-processes the given text.\n",
    "  Args:\n",
    "      text (str): Text to process\n",
    "  Returns:\n",
    "      str: Processed text\n",
    "  \"\"\"\n",
    "  result_text = text\n",
    "  result_text = clean_html(result_text)\n",
    "  result_text = result_text.lower()\n",
    "  pattern = r\"(?<![a-zA-Z])[^\\w\\s]|[^\\w\\s](?![a-zA-Z])\"\n",
    "  result_text = re.sub(pattern, \"\", result_text)\n",
    "  result_text = result_text.strip()\n",
    "  return re.sub(\"(\\s+)\", \" \", result_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiny test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocessing(input: str, expected: str) -> None:\n",
    "    result: str = text_processing(input)\n",
    "    assert text_processing(input) == expected or print(result)\n",
    "\n",
    "test_preprocessing(\"Hello, ,,,World!::\", \"hello world\")\n",
    "test_preprocessing(\"Hello,        U.S.A!\", \"hello u.s.a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply `text_processing` function on our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"i had high hopes for this one until they changed the name to the shepherd border patrol the lamest movie name ever what was wrong with just the shepherd this is a by the numbers action flick that tips its hat at many classic van damme films there is a nice bit of action in a bar which reminded me of hard target and universal soldier but directed with no intensity or flair which is a shame there is one great line about being p*ss drunk and carrying a rabbit and some ok action scenes let down by the cheapness of it all a lot of the times the dialogue doesn't match the characters mouth and the stunt men fall down dead a split second before even being shot the end fight is one of the better van damme fights except the director tries to go a bit too john woo and fails also introducing flashbacks which no one really cares about just gets in the way of the action which is the whole point of a van damme film.not good not bad just average generic action\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_frame.text = train_data_frame.text.apply(text_processing)\n",
    "train_data_frame.text[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
