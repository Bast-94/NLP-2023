{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import datasets as ds\n",
    "from collections import Counter\n",
    "\n",
    "from scripts import data\n",
    "from scripts.naive_bayes import from_scratch as naive_bayes\n",
    "from scripts.naive_bayes import scikit_learn as sk_naive_bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "How many splits does the dataset has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits:\n",
      "'train'\n",
      "'test'\n",
      "'unsupervised'\n",
      "Number of splits: 3\n"
     ]
    }
   ],
   "source": [
    "splits: list[str] = ds.get_dataset_split_names('imdb')\n",
    "print('Splits:')\n",
    "for split in splits:\n",
    "    print(f'\\'{split}\\'')\n",
    "print(f'Number of splits: {len(splits)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 splits in the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "How big are these splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "'train' split size : 25000\n",
      "'test' split size : 25000\n",
      "'unsupervised' split size : 50000\n"
     ]
    }
   ],
   "source": [
    "datasets: list[ds.Dataset] = data.load_datasets(splits=splits)\n",
    "print('Dataset sizes:')\n",
    "for i, dataset in enumerate(datasets):\n",
    "    print(f'\\'{splits[i]}\\' split size : {dataset.num_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "What is the proportion of each class on the supervised splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised dataset sizes:\n",
      "\n",
      "\n",
      "'train'\n",
      "Class 0\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "Class 1\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "'test'\n",
      "Class 0\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "Class 1\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get only supervised datasets\n",
    "supervised_datasets: list[pd.DataFrame] = data.datasets_to_dataframes(datasets[0:2])\n",
    "\n",
    "print('Supervised dataset sizes:')\n",
    "# For each dataset, print the number of samples for each class\n",
    "for i, dataset in enumerate(supervised_datasets):\n",
    "    print('\\n')\n",
    "    print(f'\\'{splits[i]}\\'')\n",
    "    print('Class 0')\n",
    "    print(dataset.where(dataset['label'] == 0).count())\n",
    "    print('Class 1')\n",
    "    print(dataset.where(dataset['label'] == 1).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, each class represents 50% of the supervised dataset (both in train and test samples)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert whether the the preprocessing gives the expected result (e.g. \"Hello, ,,,World!::\" -> \"hello world\")\n",
    "data.test_preprocessing(\"Hello, ,,,World!::\", \"hello world\")\n",
    "data.test_preprocessing(\"Hello,        U.S.A!\", \"hello u.s.a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply the preprocessing to train and test sets (supervised datasets). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i rented i am curious-yellow from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am curious yellow is a risible and pretentio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this film was probably inspired by godard's ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh brotherafter hearing about this ridiculous ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i rented i am curious-yellow from my video sto...      0\n",
       "1  i am curious yellow is a risible and pretentio...      0\n",
       "2  if only to avoid making this type of film in t...      0\n",
       "3  this film was probably inspired by godard's ma...      0\n",
       "4  oh brotherafter hearing about this ridiculous ...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = data.processed_dataframes(supervised_datasets)\n",
    "\n",
    "# Convert labels to int in the dataframes\n",
    "train_df.label = train_df.label.astype(int)\n",
    "test_df.label = test_df.label.astype(int)\n",
    "\n",
    "# Train dataset preview\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the vocabulary of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Counter collection is used to build up the vocabulary, and store with it the number of occurrences of each word\n",
    "vocabulary: Counter = naive_bayes.build_vocabulary(texts_serie=train_df.text)\n",
    "counter_class: pd.DataFrame = train_df.groupby(\"label\").agg({'text': naive_bayes.build_vocabulary})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier pseudo-code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./nbc.png\" width=\"30%\" height=\"20%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'From scratch' Naive Bayes classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Naive Bayes model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of variables `logprior, loglikelihood` represent the naive bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikelihood = naive_bayes.classifier(train_df, vocabulary, counter_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loglikelihood['love'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions\n",
    "Make prediction on each text of the training and testing sets and store them in a `'model_result'` column in the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping lambda function to apply to each row of the dataframe\n",
    "test_classifier = lambda text : naive_bayes.test_classifier(text, logprior, loglikelihood, train_df, vocabulary)\n",
    "\n",
    "train_df[\"model_result\"] = train_df.text.apply(test_classifier)\n",
    "test_df[\"model_result\"] = test_df.text.apply(test_classifier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 ('From scratch' implementation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "We are now able to get the good predictions count, hence we can get an accuracy ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes.display_accuracy(train_df, \"Train\")\n",
    "naive_bayes.display_accuracy(test_df, \"Test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = sk_naive_bayes.pipeline()\n",
    "\n",
    "# Train the model on the training set\n",
    "pipeline.fit(train_df.text, train_df.label)\n",
    "\n",
    "# Make predictions on the train and test sets\n",
    "train_predictions = pipeline.predict(train_df.text)\n",
    "test_predictions = pipeline.predict(test_df.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (scikit-learn implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classificiation report\n",
    "print('Classification report (testing):')\n",
    "sk_naive_bayes.print_classification_report(test_df, test_predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('Confusion matrix (testing):')\n",
    "sk_naive_bayes.print_confusion_matrix(test_df, test_predictions)\n",
    "print('\\n')\n",
    "\n",
    "# Print the accuracy score (training)\n",
    "_ = sk_naive_bayes.get_accuracy_score(train_df, train_predictions, 'Training')\n",
    "# Print the accuracy score (testing)\n",
    "_ = sk_naive_bayes.get_accuracy_score(test_df, test_predictions, 'Testing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the documentation of the `CountVectorizer` class, we understand that the internal implementation produces a sparse matrix using `scipy`. In some cases, sparse data can be considered as a form of regularization, limiting the number of features the model can use in order to make a predictions.\n",
    "In other terms, sparse data may help to avoid (or at least reduce) overfitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy metrics is a sufficient metric to measure the performance of our model. Indeed, the dataset is equally distributed between the classes and are well separated between positive and negative sentiments."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Here, we are taking three wrongly classified samples of our tests set and we takes result of Naive Bayes Classifier from scratch (vocabulary, loglikelihood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a text which is wrongly classified\n",
    "failed = test_df[test_df['label'] != test_df['model_result']  ].iloc[25:28]\n",
    "\n",
    "# Tokenize\n",
    "for item in failed.iloc:\n",
    "    text = item.text\n",
    "    word_list = naive_bayes.tokenize(text)\n",
    "    counter = 0\n",
    "    total_word_count = len(word_list)\n",
    "    best_like = 0\n",
    "    best_log = None\n",
    "    best_word = None\n",
    "    for word in word_list : \n",
    "        if(vocabulary[word]!=0):\n",
    "            if (best_log is None or best_log < loglikelihood[word][item.label]):\n",
    "                best_log = loglikelihood[word][item.label]\n",
    "                best_word = word \n",
    "    print(f'{best_log = }, {best_word = }, Label = {item.label}, model_result = {item.model_result}, {loglikelihood[best_word] = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model failed because a text is composed of many neutral word such as 'the' or 'and'. But the NBC can influence the result label because neutral words do not have the same loglikelihood for each class. The example above shows that for each text the word 'the' has the best loglikelihood for class '1' which can influence the class result of the NBC even if the word 'the' is neither positive nor negative. So if a frequently used and neutral word such as 'the' can influence the result it is possible that other word can do so."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i - Highest likelihood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the words with the highest likelihood in each class (if you use scikit-learn, you want to check feature_log_prob_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the most likely words\n",
    "sk_naive_bayes.print_most_likely_words(pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii - Stopwords removal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words: list[str] = data.get_stopwords()\n",
    "pipeline = sk_naive_bayes.pipeline(stop_words=stop_words)\n",
    "\n",
    "# Train the model on the training set\n",
    "pipeline.fit(train_df.text, train_df.label)\n",
    "\n",
    "# Make predictions on the train and test sets\n",
    "train_predictions = pipeline.predict(train_df.text)\n",
    "test_predictions = pipeline.predict(test_df.text)\n",
    "\n",
    "# Print the accuracy score (training)\n",
    "_ = sk_naive_bayes.get_accuracy_score(train_df, train_predictions, 'Training')\n",
    "# Print the accuracy score (testing)\n",
    "_ = sk_naive_bayes.get_accuracy_score(test_df, test_predictions, 'Testing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\alpha$ hyperparameter tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to test different values of $\\alpha$ and to keep the one that gives the best accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals = []\n",
    "test_vals = []\n",
    "alphas: np.ndarray = np.arange(0, 100, 5)\n",
    "\n",
    "for alpha in alphas:\n",
    "    stop_words: list[str] = data.get_stopwords()\n",
    "    pipeline = sk_naive_bayes.pipeline(stop_words=stop_words, alpha=alpha)\n",
    "\n",
    "    # Train the model on the training set\n",
    "    pipeline.fit(train_df.text, train_df.label)\n",
    "\n",
    "    # Make predictions on the train and test sets\n",
    "    train_predictions = pipeline.predict(train_df.text)\n",
    "    test_predictions = pipeline.predict(test_df.text)\n",
    "\n",
    "    # Print the accuracy score (training)\n",
    "    train_val = sk_naive_bayes.get_accuracy_score(train_df, train_predictions, 'Training', print_results=False)\n",
    "    # Print the accuracy score (testing)\n",
    "    test_val = sk_naive_bayes.get_accuracy_score(test_df, test_predictions, 'Testing', print_results=False)\n",
    "\n",
    "    train_vals.append(train_val)\n",
    "    test_vals.append(test_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the accuracy on the test set for each value of $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, train_vals, label='Train')\n",
    "plt.plot(alphas, test_vals, label='Test')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, the best value for $\\alpha$ is around 55 (with a step of 5 for a range from 0 to 100)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new preprocessing function is implemented in './scripts/naive_bayes/scikit_learn.py'. The text preprocessing now includes lemmatization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get supervised data and apply preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data.get_train_test_sets(dataframes=supervised_datasets)\n",
    "\n",
    "train_df.text = train_df.text.apply(data.preprocess_with_lemmatizer)\n",
    "test_df.text = test_df.text.apply(data.preprocess_with_lemmatizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = sk_naive_bayes.pipeline(stop_words=stop_words)\n",
    "\n",
    "# Train the model on the training set\n",
    "pipeline = pipeline.fit(train_df.text, train_df.label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the train and test sets\n",
    "train_predictions = pipeline.predict(train_df.text)\n",
    "test_predictions = pipeline.predict(test_df.text)\n",
    "\n",
    "# Print the accuracy score (training)\n",
    "_ = sk_naive_bayes.get_accuracy_score(train_df, train_predictions, 'Training')\n",
    "# Print the accuracy score (testing)\n",
    "_ = sk_naive_bayes.get_accuracy_score(test_df, test_predictions, 'Testing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the accuracy is slightly worse than the previous model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results with lemmatization are sligthly worse than with the previous preprocessing method (0.38% loss in train accuracy and 0.37% loss in test accuracy). This can be the result of several factors:\n",
    "* There can be some ambiguity in the lemmatization process. For instance, if we lemmatize the word 'left' into 'leave', we can lose some information about the direction in the sentence. In the case of sentiment analysis, such an ambiguity can cause wrong predictions.\n",
    "* The lemmatization process in English can sometimes result in over-stemming. As an example, the words 'fishing' and 'fish' have the same lemma: 'fish'. In some cases, the loss of distinction between words can decrease the accuracy of the model.\n",
    "\n",
    "However, lemmatization may not always affect the accuracy of the model. Here, the accuracy only dropped by ~0.4% on both the train and test sets. This can be explained by the fact that the dataset is relatively small and that the lemmatization process is not too impactful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
