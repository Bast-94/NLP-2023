{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import datasets as ds\n",
    "from collections import Counter\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "How many splits does the dataset has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test', 'unsupervised']\n",
      "Number of splits: 3\n"
     ]
    }
   ],
   "source": [
    "splits = ds.get_dataset_split_names('imdb')\n",
    "print(splits)\n",
    "print(f'Number of splits: {len(splits)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 splits in the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "How big are these splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/bastien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/home/bastien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/home/bastien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    }
   ],
   "source": [
    "dataset_0 = ds.load_dataset('imdb', split=splits[0])\n",
    "dataset_1 = ds.load_dataset('imdb', split=splits[1])\n",
    "dataset_2 = ds.load_dataset('imdb', split=splits[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split size : 25000\n",
      "test split size : 25000\n",
      "unsupervised split size : 50000\n"
     ]
    }
   ],
   "source": [
    "print(f'{splits[0]} split size : {dataset_0.num_rows}')\n",
    "print(f'{splits[1]} split size : {dataset_1.num_rows}')\n",
    "print(f'{splits[2]} split size : {dataset_2.num_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "What is the proportion of each class on the supervised splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Test\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n",
      "text     12500\n",
      "label    12500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dataset 0: Train\n",
    "train_data_frame = dataset_0.to_pandas()\n",
    "print(\"Train\")\n",
    "print(train_data_frame.where(train_data_frame['label'] == 0).count())\n",
    "print(train_data_frame.where(train_data_frame['label'] == 1).count())\n",
    "\n",
    "print(\"\\n\")\n",
    "# Dataset 1: Test\n",
    "print(\"Test\")\n",
    "test_data_frame = dataset_1.to_pandas()\n",
    "print(test_data_frame.where(test_data_frame['label'] == 0).count())\n",
    "print(test_data_frame.where(test_data_frame['label'] == 1).count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, each class represents 50% of the supervised dataset (both in train and test samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Create an adapted processing function which lower case the text and replace punctuations with text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_html(text: str) -> str:\n",
    "  \"\"\"Function which removes unuseful HTML tags of provided text.\"\"\"\n",
    "  no_html = BeautifulSoup(text).get_text()\n",
    "  return no_html\n",
    "\n",
    "def text_processing(text: str) -> str:\n",
    "  \"\"\"Function which  process provided text, it removes punctuations, unuseful spaces and html tags.\"\"\"\n",
    "  result_text = text\n",
    "  result_text = clean_html(result_text)\n",
    "  result_text = result_text.lower()\n",
    "  pattern = r\"(?<![a-zA-Z])[^\\w\\s]|[^\\w\\s](?![a-zA-Z])\"\n",
    "  result_text = re.sub(pattern, \"\", result_text)\n",
    "  result_text = result_text.strip()\n",
    "  return re.sub(\"(\\s+)\", \" \", result_text)\n",
    "\n",
    "#tiny test\n",
    "result = text_processing(\"Hello,        U.S.A!\")\n",
    "expected = 'hello u.s.a'\n",
    "assert result == expected or print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply `text_processing` function on `text` field of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame.text = train_data_frame.text.apply(text_processing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Vocabulary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize function\n",
    "Function to cut processed text into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str)-> list:\n",
    "    return [w for w in re.split(\"\\W+\", text)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe for vocabulary\n",
    "This function compute the vocabulary dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vocabulary_series(text_serie: pd.Series) -> Counter:\n",
    "    vocabulary = None\n",
    "    for text in text_serie:\n",
    "        word_list = tokenize(text=text)\n",
    "        if(vocabulary is None):\n",
    "            vocabulary =Counter(word_list)\n",
    "            continue\n",
    "        vocabulary.update(word_list)\n",
    "    return vocabulary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the vocabulary and change the label type of the train data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = compute_vocabulary_series(train_data_frame.text)\n",
    "train_data_frame.label = train_data_frame.label.astype(str)\n",
    "counter_class = train_data_frame.groupby(\"label\").agg({'text':compute_vocabulary_series})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function which returns occurence of a word of a specific class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(counter_class: pd.DataFrame, class_name: str, word: str) -> int:\n",
    "    return counter_class.loc[class_name][\"text\"][word]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of naive Bayes classifier\n",
    "\n",
    "Let's implement this pseudo code:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](nbc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words(vocabulary: Counter, c: str,counter_class: pd.DataFrame):\n",
    "    total = 0\n",
    "    for w in vocabulary:\n",
    "        total += (word_count(counter_class,c,w))\n",
    "    return total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function which affect a specified value for loglikelihood dictionnary at index `word,class_value`. It represent the loglikelihood for a word of a specific class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_loglikelihood(loglikelihood: dict, word: str, class_value:str, value_to_affect: float) -> None:\n",
    "    if (loglikelihood.get(word) is None):\n",
    "        loglikelihood[word] = {}\n",
    "    loglikelihood[word][class_value] = value_to_affect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(train_data_frame: pd.DataFrame, vocabulary: Counter, counter_class: pd.DataFrame) :\n",
    "    total_document_count = train_data_frame.text.count()\n",
    "    class_label_set = list(train_data_frame.groupby(\"label\").groups.keys())\n",
    "    logprior = {}\n",
    "    loglikelihood ={}\n",
    "    for current_class in class_label_set:\n",
    "        class_document_count = train_data_frame[train_data_frame.label == current_class].text.count()\n",
    "        logprior[current_class] = np.log(class_document_count/total_document_count)\n",
    "        counter = 0\n",
    "        total = total_words(vocabulary,current_class,counter_class) + len(vocabulary)\n",
    "        \n",
    "        for word in vocabulary:\n",
    "            count_w_c = word_count(counter_class, current_class, word) +1\n",
    "            log_like_value = np.log(count_w_c/total)\n",
    "            fill_loglikelihood(loglikelihood,word,current_class,log_like_value)\n",
    "            \n",
    "    return logprior, loglikelihood , vocabulary\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Naive Bayes classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the test function of our naive Bayes classifier which apply for one testdoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes_classifier(testdoc :str, logprior:dict, loglikelihood: dict, train_data_frame: pd.DataFrame, vocabulary: Counter) -> tuple:\n",
    "    class_set = list(train_data_frame.groupby(\"label\").groups.keys())\n",
    "    sums = {}\n",
    "    max_class = None\n",
    "    for c in class_set:\n",
    "        sums[c] = logprior[c]\n",
    "        word_list = tokenize(testdoc)\n",
    "        for w in word_list:\n",
    "            if(vocabulary[w] != 0):\n",
    "                sums[c] = sums[c] + loglikelihood[w][c]\n",
    "        if (max_class is None or sums[max_class] < sums[c]):\n",
    "            max_class = c\n",
    "        \n",
    "    return max_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data\n",
    "Make prediction on each text from `test_data_frame` and store them in `model_result`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_frame.label = test_data_frame.label.astype(str)\n",
    "logprior, loglikelihood, vocabulary =naive_bayes_classifier(train_data_frame,vocabulary,counter_class)\n",
    "test_data_frame_2 = test_data_frame\n",
    "test_nbc_function = lambda text : test_naive_bayes_classifier(text, logprior,loglikelihood,train_data_frame,vocabulary)\n",
    "test_data_frame_2[\"model_result\"] = test_data_frame_2.text.apply(test_nbc_function)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get results\n",
    "We are now able to get the good predictions count, hence we can get an accuracy ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy_ratio*100 = 82.396\n"
     ]
    }
   ],
   "source": [
    "good_predictions_count = (test_data_frame_2[test_data_frame_2.label == test_data_frame_2.model_result]).label.count()\n",
    "text_count = test_data_frame_2.text.count()\n",
    "accuracy_ratio = good_predictions_count/text_count\n",
    "print(f'{ accuracy_ratio*100 = }')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
