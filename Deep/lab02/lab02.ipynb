{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-decoder model\n",
    "\n",
    "Today you will implement a pretty decent machine translation model using the transformer and implement several decoding strategy.\n",
    "\n",
    "###  Go through the pyTorch tutorial\n",
    "\n",
    "To start with, just follow the pyTorch [language translation with nn.Transformer and torchtext tutorial](https://pytorch.org/tutorials/beginner/translation_transformer.html).\n",
    "\n",
    "To make the code turn on Google Colab, you need to update the preinstalled version of spaCy and download the small German and English spaCy models. As pyTorch doesn't seem to maintain its tutorial with their most recent changes, you also need to install torchdata.\n",
    "```\n",
    "!pip install spacy sacrebleu torchdata -U\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download de_core_news_sm\n",
    "```\n",
    "\n",
    "As the training takes time (~20min), you can start looking at the following steps while it finishes.\n",
    "\n",
    "At training, you will encounter `TypeError: ZipperIterDataPipe instance doesn't have valid length` (pyTorch doesn't update their tutorials). A workaround can be found [here](https://github.com/pytorch/tutorials/issues/1868)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "\n",
    "\n",
    "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
    "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (3.5.3)\n",
      "Requirement already satisfied: sacrebleu in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchdata in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (0.6.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (1.24.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: setuptools in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: lxml in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from sacrebleu) (4.9.2)\n",
      "Requirement already satisfied: portalocker in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from sacrebleu) (2.7.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: regex in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from sacrebleu) (2023.3.23)\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from torchdata) (1.26.15)\n",
      "Requirement already satisfied: torch==2.0.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from torchdata) (2.0.1)\n",
      "Requirement already satisfied: sympy in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (3.1)\n",
      "Requirement already satisfied: filelock in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from jinja2->spacy) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchdata) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: jinja2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.2)\n",
      "Requirement already satisfied: setuptools in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting de-core-news-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.5.0/de_core_news_sm-3.5.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from de-core-news-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.24.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rb2/miniconda3/envs/dev/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy sacrebleu torchdata -U\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'portalocker' is not defined\nThis exception is thrown by __iter__ of _MemoryCellIterDataPipe(remember_elements=1000, source_datapipe=_ChildDataPipe)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     train_iter \u001b[39m=\u001b[39m Multi30k(split\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, language_pair\u001b[39m=\u001b[39m(SRC_LANGUAGE, TGT_LANGUAGE))\n\u001b[1;32m     20\u001b[0m     \u001b[39m# Create torchtext's Vocab object\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     vocab_transform[ln] \u001b[39m=\u001b[39m build_vocab_from_iterator(yield_tokens(train_iter, ln), \n\u001b[1;32m     22\u001b[0m                                                     min_freq\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     23\u001b[0m                                                     specials\u001b[39m=\u001b[39;49mspecial_symbols,\n\u001b[1;32m     24\u001b[0m                                                     special_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     27\u001b[0m \u001b[39m# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m ln \u001b[39min\u001b[39;00m [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchtext/vocab/vocab_factory.py:98\u001b[0m, in \u001b[0;36mbuild_vocab_from_iterator\u001b[0;34m(iterator, min_freq, specials, special_first, max_tokens)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mBuild a Vocab from an iterator.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m    >>> vocab = build_vocab_from_iterator(yield_tokens(file_path), specials=[\"<unk>\"])\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m counter \u001b[39m=\u001b[39m Counter()\n\u001b[0;32m---> 98\u001b[0m \u001b[39mfor\u001b[39;00m tokens \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m     99\u001b[0m     counter\u001b[39m.\u001b[39mupdate(tokens)\n\u001b[1;32m    101\u001b[0m specials \u001b[39m=\u001b[39m specials \u001b[39mor\u001b[39;00m []\n",
      "Cell \u001b[0;32mIn[27], line 9\u001b[0m, in \u001b[0;36myield_tokens\u001b[0;34m(data_iter, language)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39myield_tokens\u001b[39m(data_iter: Iterable, language: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m      7\u001b[0m     language_index \u001b[39m=\u001b[39m {SRC_LANGUAGE: \u001b[39m0\u001b[39m, TGT_LANGUAGE: \u001b[39m1\u001b[39m}\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mfor\u001b[39;00m data_sample \u001b[39min\u001b[39;00m data_iter:\n\u001b[1;32m     10\u001b[0m         \u001b[39myield\u001b[39;00m token_transform[language](data_sample[language_index[language]])\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/sharding.py:72\u001b[0m, in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m group_num_of_instances, group_instance_id \u001b[39min\u001b[39;00m sorted_sharding_groups:\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance_id \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_of_instances \u001b[39m*\u001b[39m group_instance_id\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_of_instances \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m group_num_of_instances\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:124\u001b[0m, in \u001b[0;36mShufflerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enabled:\n\u001b[0;32m--> 124\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    125\u001b[0m             \u001b[39myield\u001b[39;00m x\n\u001b[1;32m    126\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:589\u001b[0m, in \u001b[0;36mZipperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[T_co]]:\n\u001b[1;32m    588\u001b[0m     iterators \u001b[39m=\u001b[39m [\u001b[39miter\u001b[39m(datapipe) \u001b[39mfor\u001b[39;00m datapipe \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes]\n\u001b[0;32m--> 589\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39miterators)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/plain_text_reader.py:134\u001b[0m, in \u001b[0;36mLineReaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[Str_Or_Bytes, Tuple[\u001b[39mstr\u001b[39m, Str_Or_Bytes]]]:\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mfor\u001b[39;00m path, file \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    135\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mskip_lines(file)\n\u001b[1;32m    136\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mstrip_newline(stream)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/fileopener.py:67\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/utils/common.py:210\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[0;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    208\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mode\n\u001b[0;32m--> 210\u001b[0m \u001b[39mfor\u001b[39;00m pathname \u001b[39min\u001b[39;00m pathnames:\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pathname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    212\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string type for pathname, but got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m                         \u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pathname)))\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:52\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 52\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     53\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:52\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 52\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     53\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py:454\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[39m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001b[39;00m\n\u001b[1;32m    450\u001b[0m         \u001b[39m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    455\u001b[0m         rec_uuid, record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_cell_dp\u001b[39m.\u001b[39mget_last()\n\u001b[1;32m    456\u001b[0m         original_file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_filepath_fn(record)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m filepath, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(filepath)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/selecting.py:71\u001b[0m, in \u001b[0;36mFilterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     72\u001b[0m         condition, filtered \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_returnIfTrue(data)\n\u001b[1;32m     73\u001b[0m         \u001b[39mif\u001b[39;00m condition:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/tararchiveloader.py:54\u001b[0m, in \u001b[0;36mTarArchiveLoaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[\u001b[39mstr\u001b[39m, BufferedIOBase]]:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     55\u001b[0m         validate_pathname_binary_tuple(data)\n\u001b[1;32m     56\u001b[0m         pathname, data_stream \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/fileopener.py:67\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/utils/common.py:210\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[0;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    208\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mode\n\u001b[0;32m--> 210\u001b[0m \u001b[39mfor\u001b[39;00m pathname \u001b[39min\u001b[39;00m pathnames:\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pathname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    212\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string type for pathname, but got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m                         \u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pathname)))\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py:229\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_caching_flag:\n\u001b[0;32m--> 229\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe\n\u001b[1;32m    230\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         \u001b[39m# In case of BC breaking, use RuntimeError for now. Warning is another option\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease call `end_caching()` before iteration.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py:374\u001b[0m, in \u001b[0;36m_MemoryCellIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 374\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    375\u001b[0m         item_id \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39muuid4()\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremember_elements\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:144\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next()\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_next()\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:132\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mReturn next with logic related to iterator validity, profiler, and incrementation of samples yielded.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m _check_iterator_valid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator_id)\n\u001b[0;32m--> 132\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_and_has_next_method:\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:427\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe.get_next_element_by_instance\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_next(instance_id)\n\u001b[1;32m    428\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_child_stop[instance_id] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:396\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe._find_next\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datapipe_iterator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_datapipe_iterator has not been set, likely because this private method is called directly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwithout invoking get_next_element_by_instance() first.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 396\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datapipe_iterator)\n\u001b[1;32m    397\u001b[0m classification \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier_fn(value)\n\u001b[1;32m    398\u001b[0m \u001b[39mif\u001b[39;00m classification \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_none:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:144\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next()\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_next()\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:132\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mReturn next with logic related to iterator validity, profiler, and incrementation of samples yielded.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m _check_iterator_valid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator_id)\n\u001b[0;32m--> 132\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_and_has_next_method:\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:163\u001b[0m, in \u001b[0;36m_ForkerIterDataPipe.get_next_element_by_instance\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleading_ptr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchild_pointers[instance_id]\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     return_val \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datapipe_iterator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39mappend(return_val)\n\u001b[1;32m    165\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:52\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 52\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     53\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:52\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 52\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     53\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py:454\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[39m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001b[39;00m\n\u001b[1;32m    450\u001b[0m         \u001b[39m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    455\u001b[0m         rec_uuid, record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_cell_dp\u001b[39m.\u001b[39mget_last()\n\u001b[1;32m    456\u001b[0m         original_file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_filepath_fn(record)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m filepath, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(filepath)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/hashchecker.py:67\u001b[0m, in \u001b[0;36mHashCheckerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[\u001b[39mstr\u001b[39m, StreamWrapper]]:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mfor\u001b[39;00m file_name, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     68\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhash_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msha256\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     69\u001b[0m             hash_func \u001b[39m=\u001b[39m hashlib\u001b[39m.\u001b[39msha256()\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/load/online.py:84\u001b[0m, in \u001b[0;36mHTTPReaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[\u001b[39mstr\u001b[39m, StreamWrapper]]:\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     85\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[39myield\u001b[39;00m _get_response_from_http(url, timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py:229\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_caching_flag:\n\u001b[0;32m--> 229\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe\n\u001b[1;32m    230\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         \u001b[39m# In case of BC breaking, use RuntimeError for now. Warning is another option\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease call `end_caching()` before iteration.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py:374\u001b[0m, in \u001b[0;36m_MemoryCellIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 374\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    375\u001b[0m         item_id \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39muuid4()\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremember_elements\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:144\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next()\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_next()\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/_hook_iterator.py:132\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mReturn next with logic related to iterator validity, profiler, and incrementation of samples yielded.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m _check_iterator_valid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator_id)\n\u001b[0;32m--> 132\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_and_has_next_method:\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:427\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe.get_next_element_by_instance\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_next(instance_id)\n\u001b[1;32m    428\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_child_stop[instance_id] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:397\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe._find_next\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_datapipe_iterator has not been set, likely because this private method is called directly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwithout invoking get_next_element_by_instance() first.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    396\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datapipe_iterator)\n\u001b[0;32m--> 397\u001b[0m classification \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassifier_fn(value)\n\u001b[1;32m    398\u001b[0m \u001b[39mif\u001b[39;00m classification \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_none:\n\u001b[1;32m    399\u001b[0m     StreamWrapper\u001b[39m.\u001b[39mclose_streams(value)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py:262\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe._cache_check_fn\u001b[0;34m(data, filepath_fn, hash_dict, hash_type, extra_check_fn, cache_uuid)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(dirname):\n\u001b[1;32m    260\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(dirname)\n\u001b[0;32m--> 262\u001b[0m \u001b[39mwith\u001b[39;00m portalocker\u001b[39m.\u001b[39mLock(promise_filepath, \u001b[39m\"\u001b[39m\u001b[39ma+\u001b[39m\u001b[39m\"\u001b[39m, flags\u001b[39m=\u001b[39mportalocker\u001b[39m.\u001b[39mLockFlags\u001b[39m.\u001b[39mEXCLUSIVE) \u001b[39mas\u001b[39;00m promise_fh:\n\u001b[1;32m    263\u001b[0m     promise_fh\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m    264\u001b[0m     data \u001b[39m=\u001b[39m promise_fh\u001b[39m.\u001b[39mread()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'portalocker' is not defined\nThis exception is thrown by __iter__ of _MemoryCellIterDataPipe(remember_elements=1000, source_datapipe=_ChildDataPipe)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln), \n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "    \n",
    "\n",
    "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "  vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'de'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m0\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m SRC_VOCAB_SIZE \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(vocab_transform[SRC_LANGUAGE])\n\u001b[1;32m      4\u001b[0m TGT_VOCAB_SIZE \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(vocab_transform[TGT_LANGUAGE])\n\u001b[1;32m      5\u001b[0m EMB_SIZE \u001b[39m=\u001b[39m \u001b[39m512\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'de'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 18\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "\n",
    "\n",
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
