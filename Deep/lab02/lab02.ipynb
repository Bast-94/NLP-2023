{"cells":[{"cell_type":"markdown","metadata":{"id":"Y-b_Iy44E_gP"},"source":["## Encoder-decoder model\n","\n","Today you will implement a pretty decent machine translation model using the transformer and implement several decoding strategy.\n","\n","###  Go through the pyTorch tutorial\n","\n","To start with, just follow the pyTorch [language translation with nn.Transformer and torchtext tutorial](https://pytorch.org/tutorials/beginner/translation_transformer.html).\n","\n","To make the code turn on Google Colab, you need to update the preinstalled version of spaCy and download the small German and English spaCy models. As pyTorch doesn't seem to maintain its tutorial with their most recent changes, you also need to install torchdata.\n","```\n","!pip install spacy sacrebleu torchdata -U\n","!python -m spacy download en_core_web_sm\n","!python -m spacy download de_core_news_sm\n","```\n","\n","As the training takes time (~20min), you can start looking at the following steps while it finishes.\n","\n","At training, you will encounter `TypeError: ZipperIterDataPipe instance doesn't have valid length` (pyTorch doesn't update their tutorials). A workaround can be found [here](https://github.com/pytorch/tutorials/issues/1868)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5976,"status":"ok","timestamp":1684965142612,"user":{"displayName":"Raphael Bennaim","userId":"01443448230997044883"},"user_tz":-120},"id":"lnivTQRZJ21P","outputId":"cf9524d0-d1a2-43ee-d318-4656a457a0c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting portalocker\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Installing collected packages: portalocker\n","Successfully installed portalocker-2.7.0\n"]}],"source":["!pip install portalocker"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2uES--9eE_gR"},"outputs":[],"source":["from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.datasets import multi30k, Multi30k\n","from typing import Iterable, List\n","\n","\n","# We need to modify the URLs for the dataset since the links to the original dataset are broken\n","# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n","multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n","multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n","\n","SRC_LANGUAGE = 'de'\n","TGT_LANGUAGE = 'en'\n","\n","# Place-holders\n","token_transform = {}\n","vocab_transform = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43538,"status":"ok","timestamp":1684965190079,"user":{"displayName":"Raphael Bennaim","userId":"01443448230997044883"},"user_tz":-120},"id":"nB2F994yE_gR","outputId":"d3874d69-2587-492b-f6a0-d3e0c8b88239"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n","Collecting spacy\n","  Downloading spacy-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacrebleu\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.6.1)\n","Requirement already satisfied: spacy-legacy\u003c3.1.0,\u003e=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n","Requirement already satisfied: murmurhash\u003c1.1.0,\u003e=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n","Requirement already satisfied: cymem\u003c2.1.0,\u003e=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n","Requirement already satisfied: preshed\u003c3.1.0,\u003e=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n","Requirement already satisfied: thinc\u003c8.2.0,\u003e=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n","Requirement already satisfied: wasabi\u003c1.2.0,\u003e=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n","Requirement already satisfied: srsly\u003c3.0.0,\u003e=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n","Requirement already satisfied: catalogue\u003c2.1.0,\u003e=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: typer\u003c0.8.0,\u003e=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n","Requirement already satisfied: pathy\u003e=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: smart-open\u003c7.0.0,\u003e=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n","Requirement already satisfied: tqdm\u003c5.0.0,\u003e=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n","Requirement already satisfied: numpy\u003e=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n","Requirement already satisfied: requests\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,\u003c1.11.0,\u003e=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n","Requirement already satisfied: langcodes\u003c4.0.0,\u003e=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.7.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2022.10.31)\n","Requirement already satisfied: tabulate\u003e=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.8.10)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.2)\n","Requirement already satisfied: urllib3\u003e=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (1.26.15)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-\u003etorchdata) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-\u003etorchdata) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-\u003etorchdata) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-\u003etorchdata) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-\u003etorchdata) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch==2.0.1-\u003etorchdata) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch==2.0.1-\u003etorchdata) (16.0.5)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy) (2.0.12)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy) (3.4)\n","Requirement already satisfied: blis\u003c0.8.0,\u003e=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc\u003c8.2.0,\u003e=8.1.8-\u003espacy) (0.7.9)\n","Requirement already satisfied: confection\u003c1.0.0,\u003e=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc\u003c8.2.0,\u003e=8.1.8-\u003espacy) (0.0.4)\n","Requirement already satisfied: click\u003c9.0.0,\u003e=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer\u003c0.8.0,\u003e=0.3.0-\u003espacy) (8.1.3)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003espacy) (2.1.2)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch==2.0.1-\u003etorchdata) (1.3.0)\n","Installing collected packages: colorama, sacrebleu, spacy\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.5.2\n","    Uninstalling spacy-3.5.2:\n","      Successfully uninstalled spacy-3.5.2\n","Successfully installed colorama-0.4.6 sacrebleu-2.3.1 spacy-3.5.3\n","2023-05-24 21:52:40.227927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-24 21:52:41.535816: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-05-24 21:52:42.806771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 21:52:42.807259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 21:52:42.807433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-sm==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy\u003c3.6.0,\u003e=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.3)\n","Requirement already satisfied: spacy-legacy\u003c3.1.0,\u003e=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (1.0.4)\n","Requirement already satisfied: murmurhash\u003c1.1.0,\u003e=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (1.0.9)\n","Requirement already satisfied: cymem\u003c2.1.0,\u003e=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (2.0.7)\n","Requirement already satisfied: preshed\u003c3.1.0,\u003e=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (3.0.8)\n","Requirement already satisfied: thinc\u003c8.2.0,\u003e=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (8.1.9)\n","Requirement already satisfied: wasabi\u003c1.2.0,\u003e=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (1.1.1)\n","Requirement already satisfied: srsly\u003c3.0.0,\u003e=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (2.4.6)\n","Requirement already satisfied: catalogue\u003c2.1.0,\u003e=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (2.0.8)\n","Requirement already satisfied: typer\u003c0.8.0,\u003e=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (0.7.0)\n","Requirement already satisfied: pathy\u003e=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (0.10.1)\n","Requirement already satisfied: smart-open\u003c7.0.0,\u003e=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (6.3.0)\n","Requirement already satisfied: tqdm\u003c5.0.0,\u003e=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (4.65.0)\n","Requirement already satisfied: numpy\u003e=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (1.22.4)\n","Requirement already satisfied: requests\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (2.27.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,\u003c1.11.0,\u003e=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (1.10.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (67.7.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (23.1)\n","Requirement already satisfied: langcodes\u003c4.0.0,\u003e=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (3.3.0)\n","Requirement already satisfied: typing-extensions\u003e=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,\u003c1.11.0,\u003e=1.7.4-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (4.5.0)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (1.26.15)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (2.0.12)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (3.4)\n","Requirement already satisfied: blis\u003c0.8.0,\u003e=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc\u003c8.2.0,\u003e=8.1.8-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (0.7.9)\n","Requirement already satisfied: confection\u003c1.0.0,\u003e=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc\u003c8.2.0,\u003e=8.1.8-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (0.0.4)\n","Requirement already satisfied: click\u003c9.0.0,\u003e=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer\u003c0.8.0,\u003e=0.3.0-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003een-core-web-sm==3.5.0) (2.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","2023-05-24 21:52:56.468649: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-24 21:52:57.889835: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-05-24 21:52:59.659380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 21:52:59.659803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 21:52:59.659993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting de-core-news-sm==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.5.0/de_core_news_sm-3.5.0-py3-none-any.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy\u003c3.6.0,\u003e=3.5.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.5.0) (3.5.3)\n","Requirement already satisfied: spacy-legacy\u003c3.1.0,\u003e=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (1.0.4)\n","Requirement already satisfied: murmurhash\u003c1.1.0,\u003e=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (1.0.9)\n","Requirement already satisfied: cymem\u003c2.1.0,\u003e=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (2.0.7)\n","Requirement already satisfied: preshed\u003c3.1.0,\u003e=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (3.0.8)\n","Requirement already satisfied: thinc\u003c8.2.0,\u003e=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (8.1.9)\n","Requirement already satisfied: wasabi\u003c1.2.0,\u003e=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (1.1.1)\n","Requirement already satisfied: srsly\u003c3.0.0,\u003e=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (2.4.6)\n","Requirement already satisfied: catalogue\u003c2.1.0,\u003e=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (2.0.8)\n","Requirement already satisfied: typer\u003c0.8.0,\u003e=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (0.7.0)\n","Requirement already satisfied: pathy\u003e=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (0.10.1)\n","Requirement already satisfied: smart-open\u003c7.0.0,\u003e=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (6.3.0)\n","Requirement already satisfied: tqdm\u003c5.0.0,\u003e=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (4.65.0)\n","Requirement already satisfied: numpy\u003e=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (1.22.4)\n","Requirement already satisfied: requests\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (2.27.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,\u003c1.11.0,\u003e=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (1.10.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (67.7.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (23.1)\n","Requirement already satisfied: langcodes\u003c4.0.0,\u003e=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (3.3.0)\n","Requirement already satisfied: typing-extensions\u003e=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,\u003c1.11.0,\u003e=1.7.4-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (4.5.0)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (1.26.15)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (2.0.12)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (3.4)\n","Requirement already satisfied: blis\u003c0.8.0,\u003e=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc\u003c8.2.0,\u003e=8.1.8-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (0.7.9)\n","Requirement already satisfied: confection\u003c1.0.0,\u003e=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc\u003c8.2.0,\u003e=8.1.8-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (0.0.4)\n","Requirement already satisfied: click\u003c9.0.0,\u003e=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer\u003c0.8.0,\u003e=0.3.0-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003espacy\u003c3.6.0,\u003e=3.5.0-\u003ede-core-news-sm==3.5.0) (2.1.2)\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-3.5.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n"]}],"source":["!pip install spacy sacrebleu torchdata -U\n","!python -m spacy download en_core_web_sm\n","!python -m spacy download de_core_news_sm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"veYXdlE2E_gS"},"outputs":[],"source":["\n","\n","token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n","token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n","\n","\n","# helper function to yield list of tokens\n","def yield_tokens(data_iter: Iterable, language: str) -\u003e List[str]:\n","    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n","\n","    for data_sample in data_iter:\n","        yield token_transform[language](data_sample[language_index[language]])\n","\n","# Define special symbols and indices\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n","# Make sure the tokens are in order of their indices to properly insert them in vocab\n","special_symbols = ['\u003cunk\u003e', '\u003cpad\u003e', '\u003cbos\u003e', '\u003ceos\u003e']\n","\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    # Training data Iterator\n","    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","    # Create torchtext's Vocab object\n","    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n","                                                    min_freq=1,\n","                                                    specials=special_symbols,\n","                                                    special_first=True)\n","\n","# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n","# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","  vocab_transform[ln].set_default_index(UNK_IDX)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jcF_j0BGE_gS"},"outputs":[],"source":["from torch import Tensor\n","import torch\n","import torch.nn as nn\n","from torch.nn import Transformer\n","import math\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n","class PositionalEncoding(nn.Module):\n","    def __init__(self,\n","                 emb_size: int,\n","                 dropout: float,\n","                 maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        pos_embedding = torch.zeros((maxlen, emb_size))\n","        pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        pos_embedding = pos_embedding.unsqueeze(-2)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding', pos_embedding)\n","\n","    def forward(self, token_embedding: Tensor):\n","        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n","\n","# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","\n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n","\n","# Seq2Seq Network\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(self,\n","                 num_encoder_layers: int,\n","                 num_decoder_layers: int,\n","                 emb_size: int,\n","                 nhead: int,\n","                 src_vocab_size: int,\n","                 tgt_vocab_size: int,\n","                 dim_feedforward: int = 512,\n","                 dropout: float = 0.1):\n","        super(Seq2SeqTransformer, self).__init__()\n","        self.transformer = Transformer(d_model=emb_size,\n","                                       nhead=nhead,\n","                                       num_encoder_layers=num_encoder_layers,\n","                                       num_decoder_layers=num_decoder_layers,\n","                                       dim_feedforward=dim_feedforward,\n","                                       dropout=dropout)\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(\n","            emb_size, dropout=dropout)\n","\n","    def forward(self,\n","                src: Tensor,\n","                trg: Tensor,\n","                src_mask: Tensor,\n","                tgt_mask: Tensor,\n","                src_padding_mask: Tensor,\n","                tgt_padding_mask: Tensor,\n","                memory_key_padding_mask: Tensor):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n","                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n","        return self.generator(outs)\n","\n","    def encode(self, src: Tensor, src_mask: Tensor):\n","        return self.transformer.encoder(self.positional_encoding(\n","                            self.src_tok_emb(src)), src_mask)\n","\n","    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n","        return self.transformer.decoder(self.positional_encoding(\n","                          self.tgt_tok_emb(tgt)), memory,\n","                          tgt_mask)"]},{"cell_type":"markdown","metadata":{"id":"YpOLHMcVLavs"},"source":["During training, we need a subsequent word mask that will prevent the model from looking into the future words when making predictions. We will also need masks to hide source and target padding tokens. Below, let's define a function that will take care of both."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vco29dU7LbWk"},"outputs":[],"source":["def generate_square_subsequent_mask(sz):\n","    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","\n","\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[0]\n","    tgt_seq_len = tgt.shape[0]\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n","\n","    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n","    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"]},{"cell_type":"markdown","metadata":{"id":"NybAChyaLjVr"},"source":["Let's now define the parameters of our model and instantiate the same. Below, we also define our loss function which is the cross-entropy loss and the optimizer used for training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JMgsjs48LmeX"},"outputs":[],"source":["torch.manual_seed(0)\n","\n","SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n","TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n","EMB_SIZE = 512\n","NHEAD = 8\n","FFN_HID_DIM = 512\n","BATCH_SIZE = 128\n","NUM_ENCODER_LAYERS = 3\n","NUM_DECODER_LAYERS = 3\n","\n","transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n","                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n","\n","for p in transformer.parameters():\n","    if p.dim() \u003e 1:\n","        nn.init.xavier_uniform_(p)\n","\n","transformer = transformer.to(DEVICE)\n","\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","\n","optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"]},{"cell_type":"markdown","metadata":{"id":"A-S73PwZLsy4"},"source":["As seen in the Data Sourcing and Processing section, our data iterator yields a pair of raw strings. We need to convert these string pairs into the batched tensors that can be processed by our Seq2Seq network defined previously. Below we define our collate function that converts a batch of raw strings into batch tensors that can be fed directly into our model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23NUAsPeLtTN"},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","# helper function to club together sequential operations\n","def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","# function to add BOS/EOS and create tensor for input sequence indices\n","def tensor_transform(token_ids: List[int]):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.tensor(token_ids),\n","                      torch.tensor([EOS_IDX])))\n","\n","# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n","text_transform = {}\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n","                                               vocab_transform[ln], #Numericalization\n","                                               tensor_transform) # Add BOS/EOS and create tensor\n","\n","\n","# function to collate data samples into batch tensors\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n","        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n","    return src_batch, tgt_batch"]},{"cell_type":"markdown","metadata":{"id":"3bIXmJMELzec"},"source":["Let's define training and evaluation loop that will be called for each epoch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkdSocRALvtg"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def train_epoch(model, optimizer):\n","    model.train()\n","    losses = 0\n","    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","\n","    for src, tgt in train_dataloader:\n","        src = src.to(DEVICE)\n","        tgt = tgt.to(DEVICE)\n","\n","        tgt_input = tgt[:-1, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        optimizer.zero_grad()\n","\n","        tgt_out = tgt[1:, :]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        losses += loss.item()\n","\n","    return losses / len(list(train_dataloader))\n","\n","\n","def evaluate(model):\n","    model.eval()\n","    losses = 0\n","\n","    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","\n","    for src, tgt in val_dataloader:\n","        src = src.to(DEVICE)\n","        tgt = tgt.to(DEVICE)\n","\n","        tgt_input = tgt[:-1, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        tgt_out = tgt[1:, :]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        losses += loss.item()\n","\n","    return losses / len(list(val_dataloader))"]},{"cell_type":"markdown","metadata":{"id":"FRtdkaQsL4iJ"},"source":["Now we have all the ingredients to train our model. Let's do it!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"WZ7oyYmvL2Gq"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n","  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, Train loss: 5.344, Val loss: 4.114, Epoch time = 48.016s\n","Epoch: 2, Train loss: 3.760, Val loss: 3.320, Epoch time = 43.748s\n","Epoch: 3, Train loss: 3.161, Val loss: 2.895, Epoch time = 45.301s\n","Epoch: 4, Train loss: 2.768, Val loss: 2.639, Epoch time = 45.147s\n","Epoch: 5, Train loss: 2.480, Val loss: 2.443, Epoch time = 44.686s\n","Epoch: 6, Train loss: 2.251, Val loss: 2.318, Epoch time = 44.393s\n","Epoch: 7, Train loss: 2.061, Val loss: 2.201, Epoch time = 44.952s\n","Epoch: 8, Train loss: 1.897, Val loss: 2.112, Epoch time = 45.272s\n","Epoch: 9, Train loss: 1.754, Val loss: 2.061, Epoch time = 45.117s\n","Epoch: 10, Train loss: 1.631, Val loss: 2.002, Epoch time = 44.288s\n","Epoch: 11, Train loss: 1.524, Val loss: 1.969, Epoch time = 44.823s\n","Epoch: 12, Train loss: 1.419, Val loss: 1.942, Epoch time = 45.467s\n","Epoch: 13, Train loss: 1.334, Val loss: 1.968, Epoch time = 45.467s\n","Epoch: 14, Train loss: 1.252, Val loss: 1.944, Epoch time = 44.362s\n","Epoch: 15, Train loss: 1.173, Val loss: 1.933, Epoch time = 44.504s\n","Epoch: 16, Train loss: 1.103, Val loss: 1.922, Epoch time = 44.888s\n","Epoch: 17, Train loss: 1.039, Val loss: 1.899, Epoch time = 45.843s\n","Epoch: 18, Train loss: 0.979, Val loss: 1.906, Epoch time = 44.848s\n"]}],"source":["from timeit import default_timer as timer\n","NUM_EPOCHS = 18\n","\n","for epoch in range(1, NUM_EPOCHS+1):\n","    start_time = timer()\n","    train_loss = train_epoch(transformer, optimizer)\n","    end_time = timer()\n","    val_loss = evaluate(transformer)\n","    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Scz0B71ulIuF"},"outputs":[],"source":["import os\n","os.environ['TORCH_USE_CUDA_DSA'] = '1'\n","\n","# function to generate output sequence using greedy algorithm\n","def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    src = src.to(DEVICE)\n","    src_mask = src_mask.to(DEVICE)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len-1):\n","        memory = memory.to(DEVICE)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                    .type(torch.bool)).to(DEVICE)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.item()\n","\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","\n","# actual function to translate input sentence into target language\n","def translate(model: torch.nn.Module, src_sentence: str):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n","    num_tokens = src.shape[0]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n","    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"\u003cbos\u003e\", \"\").replace(\"\u003ceos\u003e\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WxOMfNTWL7FV"},"outputs":[{"name":"stdout","output_type":"stream","text":[" A group of people standing in front of an igloo . \n"]}],"source":["print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"]},{"cell_type":"markdown","metadata":{"id":"62ziFUx8akEJ"},"source":["### **(4 points)** Theoretical questions\n","\n","Answer the following questions.\n","\n","* In the positional encoding, why are we using a combination of sinus and cosinus?\n","* In the `Seq2SeqTransformer` class,\n","  * What is the parameter nhead for?\n","  * What is the point of the `generator`?\n","* Describe the goal of the `create_mask` function. Why does it handle differently the source and target masks?"]},{"cell_type":"markdown","metadata":{"id":"0d9Q4tSJapAh"},"source":["`In the positional encoding, why are we using a combination of sinus and cosinus ?`\n","\n","The use of sine and cosine functions in positional encoding is a strategy to embed the positional information of tokens in the sequence. It's important to note that the purpose of this positional encoding is to allow the model to learn to use this information, rather than explicitly tell the model the absolute position of each token.\n","\n","Here's a more detailed explanation of why we use a combination of sine and cosine functions:\n","\n","Uniqueness: Each position gets a unique positional encoding. With the combination of sine and cosine functions of different frequencies, we can represent the positional information uniquely. Moreover, these positional encodings can be learned and are able to generalize to sequence lengths longer than the ones encountered during training.\n","\n","Relative positions: The Transformer model needs to understand not just the absolute position of the tokens in a sequence, but also the relative positions between tokens. The sine and cosine functions have a repeating pattern, which provides a way to capture the concept of relative position. More technically, for any fixed offset k, PE(pos+k) can be represented as a linear function of PE(pos).\n","\n","Continuous representation: While the absolute position of each token could be included as a simple integer (1, 2, 3, ...), this would be a large, sparse vector and might not be as effectively learned by the model. Sinusoidal functions provide a smooth, continuous representation that may be easier for the model to generalize.\n","\n","They don't require a lot of memory: Unlike some other methods for encoding position, the sinusoidal method doesn't require any learned parameters. This makes it efficient and scalable.\n","\n","The choice of sine for even indices and cosine for odd indices is somewhat arbitrary; it's just a way to get two different signals that may be easier for the model to distinguish.\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GzndukYDa2nm"},"source":["`In the SEQ2SEQTRANSFORMER class`\n","\n","* What is the parameter nhead for?\n","\n","In the context of the Seq2SeqTransformer class and specifically the Transformer model in PyTorch, the nhead parameter stands for the number of heads in the multi-head self-attention mechanisms.\n","\n","The Transformer uses a mechanism called self-attention, where it calculates an attention score for each input in the context of the entire sequence. The concept of multi-head attention means that this process is not done once but multiple times in parallel, with each \"head\" potentially learning to pay attention to different aspects of the input.\n","\n","Each head gets a portion of the input representation, performs self-attention independently, and then the results are concatenated and linearly transformed to result in the final output.\n","\n","In essence, nhead controls the number of distinct representation spaces the model can learn from and can help the model capture various aspects of the input data at different levels of abstraction. It's a hyperparameter that you can tune to optimize performance.\n","\n","In practice, you often see nhead set to 8 or 16 in Transformer models. This means that the self-attention mechanism is applied 8 or 16 times in parallel to each input. Each of these heads may learn to pay attention to different features in the data, thus helping to improve the model's performance.\n","\n","* What is the point of the generator?\n","\n","The generator is a linear layer that maps the model's output back to the size of the vocabulary. It is applied to the output of the decoder's self-attention layer and the encoder-decoder attention layer.\n","\n","The purpose of this is to transform the high-dimensional encoder-decoder output into a space that matches the number of classes (i.e., the size of the target vocabulary) that the model needs to predict. This is typically done by a linear (also known as fully connected) layer.\n","\n","* Describe the goal of the `create_mask` function. Why does it handle differently the source and target masks?\n","\n","The create_mask function creates four different masks, each serving a different purpose in the transformer architecture. These masks are utilized in the transformer to prevent attention to certain tokens : \n","\n","* `src_mask`: This mask is a square matrix of zeros. It's designed to be applied on source sequences in the encoder. In this particular implementation, all source tokens can attend to all other tokens (there's no masking in the encoder apart from padding), hence all values in the mask are zero.\n","\n","* `tgt_mask`: This is a \"look-ahead\" mask or \"future\" mask for the target sequences. It's used in the decoder to prevent a token from attending to future tokens in the same sequence, which enforces the autoregressive property. This mask is generated using the generate_square_subsequent_mask function which creates a square matrix with ones below the diagonal and zeros on and above the diagonal. The ones are then replaced with zeros and the zeros with negative infinity. The negative infinity values ensure that, after applying a softmax, these positions yield a near zero attention score, effectively masking them.\n","\n","* `src_padding_mask` and `tgt_padding_mask`: These masks are used to prevent the model from paying attention to padding tokens in the source and target sequences, respectively. They are generated by comparing each token in the source and target sequences to the padding index (PAD_IDX); a True (or 1) is output where there's a pad token and a False (or 0) elsewhere.\n","\n","The reason for different handling between source and target masks is due to the distinct roles of the encoder and decoder:\n","\n","The encoder processes the entire input sequence at once and thus needs to mask only the padding tokens (using src_padding_mask), not future tokens, so there's no need for a look-ahead mask.\n","The decoder, on the other hand, is designed to generate each token one at a time, conditioned on previous tokens. Therefore, it needs the look-ahead mask (tgt_mask) to prevent each token from seeing future tokens, and also the padding mask (tgt_padding_mask) to ignore pad tokens. This is why the target mask is more complex and created differently from the source mask.\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JXDtAOjIcEyw"},"source":["### **(6 points)** Decoding functions  \n","The tutorial uses a greedy approach at decoding. Implement the following variations.\n","* (3 points) A top-k sampling with temperature.\n","* (1 point) A top-p sampling with temperature.\n","* (2 point) Play with the k, p and temperature parameters, and qualitatively compare a few (at least 3) translation samples for each approach (even the greedy one).\n"]},{"cell_type":"markdown","metadata":{"id":"JyEOUBPWhGPn"},"source":["`Top-k sampling with temperature`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lCgDPG8ZhL_N"},"outputs":[],"source":["def top_k_sampling_decode(model, src, src_mask, max_len, start_symbol, k=10, temperature=1.0):\n","    src = src.to(DEVICE)\n","    src_mask = src_mask.to(DEVICE)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len-1):\n","        memory = memory.to(DEVICE)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                    .type(torch.bool)).to(DEVICE)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        logits = model.generator(out[:, -1])\n","        \n","        # Apply temperature\n","        logits = logits / temperature\n","        \n","        # Top-k sampling\n","        indices_to_remove = logits \u003c torch.topk(logits, k)[0][..., -1, None]\n","        logits[indices_to_remove] = float('-inf')\n","        \n","        probs = torch.nn.functional.softmax(logits, dim=-1)\n","        next_word = torch.multinomial(probs, num_samples=1)\n","        next_word = next_word.item()\n","\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","# actual function to translate input sentence into target language\n","def translate_k(model: torch.nn.Module, src_sentence: str, k=10, temperature=1.0):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n","    num_tokens = src.shape[0]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = top_k_sampling_decode(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, k=k, temperature=temperature).flatten()\n","    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"\u003cbos\u003e\", \"\").replace(\"\u003ceos\u003e\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3MZmhPMxhP3b"},"outputs":[],"source":["print(translate_k(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"]},{"cell_type":"markdown","metadata":{"id":"L1SYgEN-iPL_"},"source":["Top-k sampling introduces an element of randomness in the generation process which leads to different outputs even for the same input."]},{"cell_type":"markdown","metadata":{"id":"QQXLo1gYimHs"},"source":["`Top-p sampling with temperature`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBzA4q5Dir2L"},"outputs":[],"source":["def top_p_sampling_decode(model, src, src_mask, max_len, start_symbol, p=0.9, temperature=1.0):\n","    src = src.to(DEVICE)\n","    src_mask = src_mask.to(DEVICE)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len-1):\n","        memory = memory.to(DEVICE)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                    .type(torch.bool)).to(DEVICE)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        logits = model.generator(out[:, -1])\n","\n","        # Apply temperature\n","        logits = logits / temperature\n","\n","        # Convert logits to probabilities\n","        probs = torch.nn.functional.softmax(logits, dim=-1)\n","\n","        # Sort probabilities\n","        sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n","\n","        # Get the smallest set of tokens whose cumulative probability exceeds p\n","        cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n","        sorted_indices_to_remove = cumulative_probs \u003e p\n","        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n","        sorted_indices_to_remove[..., 0] = 0\n","\n","        # Create a new probabilities tensor to sample from\n","        new_probs = probs.clone()\n","        new_probs[sorted_indices[sorted_indices_to_remove]] = 0\n","\n","        next_word = torch.multinomial(new_probs, num_samples=1)\n","        next_word = next_word.item()\n","\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","def translate_top_p(model: torch.nn.Module, src_sentence: str, p=0.9, temperature=1.0):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n","    num_tokens = src.shape[0]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = top_p_sampling_decode(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, p=p, temperature=temperature).flatten()\n","    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"\u003cbos\u003e\", \"\").replace(\"\u003ceos\u003e\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTkEaYUBizUD"},"outputs":[],"source":["print(translate_top_p(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", p=0.9, temperature=1.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7vzdTstoi2rU"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"dev","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}