{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing 01 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 03"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features (6 points)\n",
    "\n",
    "For every given text, we want to generate a vector with the features seen in class.\n",
    "\n",
    "**(6 points)** Code the following features:\n",
    "* 1 if \"no\" appears in the document, 0 otherwise.\n",
    "* The count of first and second pronouns in the document.\n",
    "* 1 if \"!\" is in the document, 0 otherwise.\n",
    "* Log(word count in the document).\n",
    "* Number of words in the document which are in the positive lexicon.\n",
    "* Number of words in the document which are in the negative lexicon.\n",
    "* **\\[Bonus\\]** Add another feature of your choice.\n",
    "\n",
    "For positive and negative lexicons, you can use the resources provided by [VADER sentiment](https://github.com/cjhutto/vaderSentiment). Look for the `vader_lexicon.txt` file and consider positive word if they score above a certain threshold (for example 1) and negative word if they score below a certain threshold (for example -1). Feel free to use another lexicon if you find one, but make sure you document your choice.\n",
    "\n",
    "\n",
    "### Tips\n",
    "\n",
    "* Don't forget to use a similar pre-treatment as the one you used for the previous lab.\n",
    "* Beware that words in the VADER dictionary are not lemmatized or stemmed. Do not use these pretreatments here.\n",
    "* When checking for occurences of \"no\" or pronouns, split the text into token. Just using `\"no\" in text` would return true if the word \"notable\" is in your text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/rb2/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/Users/rb2/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    }
   ],
   "source": [
    "import datasets as ds\n",
    "import numpy as np\n",
    "\n",
    "splits = ds.get_dataset_split_names('imdb')\n",
    "train_ds = ds.load_dataset('imdb', split=splits[0])\n",
    "test_ds = ds.load_dataset('imdb', split=splits[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/rb2/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For each given text, create a vector with the following features:\n",
    "\n",
    "# if \"no\" appears in the document, 0 otherwise.\n",
    "# The count of first pronouns (i , we) in the document.\n",
    "# The count of second pronoun (you) in the document.\n",
    "# 1 if \"!\" is in the document, 0 otherwise.\n",
    "# Log(word count in the document).\n",
    "# Number of positive words in the document.\n",
    "# Number of negative words in the document.\n",
    "\n",
    "# When checking for occurences of \"no\" or pronouns, split the text into token. Just using `\"no\" in text` would return true if the word \"notable\" is in your text.\n",
    "\n",
    "#import `vader_lexicon.txt` from https://github.com/cjhutto/vaderSentiment and display it.\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_features(text):\n",
    "    text = text.lower()\n",
    "    features = []\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    features.append(1 if \"no\" in text.split() else 0)\n",
    "    features.append(text.split().count(\"i\") + text.split().count(\"we\"))\n",
    "    features.append(text.split().count(\"you\"))\n",
    "    features.append(1 if \"!\" in text else 0)\n",
    "    features.append(np.log(len(text.split())))\n",
    "    for word in text.split():\n",
    "        if sid.lexicon.get(word, 0) < -1:\n",
    "            negative += 1\n",
    "        elif sid.lexicon.get(word, 0) > 1:\n",
    "            positive += 1\n",
    "    features.append(positive)\n",
    "    features.append(negative)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 1, 2.0794415416798357, 1, 1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features(\"I am You We  not happy NO !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
