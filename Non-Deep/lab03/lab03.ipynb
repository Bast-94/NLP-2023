{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing (1) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets as ds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "from scripts import data\n",
    "from scripts import features\n",
    "from scripts.logistic_regression.model import LogisticRegression\n",
    "from scripts.logistic_regression import lr_methods, scikit_learn_lr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features (6 points)\n",
    "\n",
    "For every given text, we want to generate a vector with the features seen in class.\n",
    "\n",
    "**(6 points)** Code the following features:\n",
    "* 1 if \"no\" appears in the document, 0 otherwise.\n",
    "* The count of first and second pronouns in the document.\n",
    "* 1 if \"!\" is in the document, 0 otherwise.\n",
    "* Log(word count in the document).\n",
    "* Number of words in the document which are in the positive lexicon.\n",
    "* Number of words in the document which are in the negative lexicon.\n",
    "* **\\[Bonus\\]** Add another feature of your choice.\n",
    "\n",
    "For positive and negative lexicons, you can use the resources provided by [VADER sentiment](https://github.com/cjhutto/vaderSentiment). Look for the `vader_lexicon.txt` file and consider positive word if they score above a certain threshold (for example 1) and negative word if they score below a certain threshold (for example -1). Feel free to use another lexicon if you find one, but make sure you document your choice.\n",
    "\n",
    "\n",
    "### Tips\n",
    "\n",
    "* Don't forget to use a similar pre-treatment as the one you used for the previous lab.\n",
    "* Beware that words in the VADER dictionary are not lemmatized or stemmed. Do not use these pretreatments here.\n",
    "* When checking for occurences of \"no\" or pronouns, split the text into token. Just using `\"no\" in text` would return true if the word \"notable\" is in your text.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    }
   ],
   "source": [
    "splits = ds.get_dataset_split_names('imdb')\n",
    "train_ds, test_ds = data.load_datasets(splits=splits[:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/francois.soulier/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sid: SentimentIntensityAnalyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply feature extraction on an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 1, 2.0794415416798357, 1, 1, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.get_features(\"I am You We  not happy NO !\", sid=sid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply features extraction on both `training` and `testing` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>first_pronouns</th>\n",
       "      <th>second_pronouns</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>log_word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>label</th>\n",
       "      <th>third_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.641907</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.365976</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.465908</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.736198</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.680173</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no  first_pronouns  second_pronouns  exclamation  log_word_count  positive  \\\n",
       "0   1               6                0            0        5.641907         7   \n",
       "1   1               1                1            0        5.365976         3   \n",
       "2   1               0                0            0        4.465908         3   \n",
       "3   0               2                1            0        4.736198         5   \n",
       "4   0               8                1            1        5.680173         4   \n",
       "\n",
       "   negative  label  third_person  \n",
       "0         5      0             8  \n",
       "1         4      0             3  \n",
       "2         3      0             4  \n",
       "3         3      0             1  \n",
       "4        11      0             9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train: pd.DataFrame = features.add_features(train_ds, sid=sid)\n",
    "df_test: pd.DataFrame = features.add_features(test_ds, sid=sid)\n",
    "\n",
    "# Result example\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the `training` dataset into a training and a validation dataset (using 10 to 20% of the training set as validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train.drop(columns=[\"label\"]), df_train[\"label\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression classifier (6 points)\n",
    "\n",
    "The `logistic_regression_pytorch.ipynb` notebook, in the same directory, shows how to train a logistic regression classifier using PyTorch on a dummy dataset.\n",
    "\n",
    "* **(3 points)** Adapt the code by adding your feature extractor and train a classifier.\n",
    "  * For training, don't use the test set as validation. Instead, split the training set into a training and a validation set (use 10 to 20% of the training set as validation).\n",
    "* **(1 point)** Evaluate your classifier in terms of accuracy for the training, validation, and test set.\n",
    "* **(1 point)** Look at the weights of your classifier. Which features seems to play most for both classes?\n",
    "* **\\[Bonus\\]** The parameter `weight_decay` of the [SGD optimizer](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) corresponds to the L2 penalty. Try playing with this value and explain how it influence the model's weights.\n",
    "* **(1 point)** Take two wrongly classified samples in the test set and try explaining why the model was wrong.\n",
    "* **\\[Bonus\\]** Train logistic regression classifier using the [scikit-learn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). How does it compare with the PyTorch version?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model, loss function and optimizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(8, 1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5083, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5937, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5937, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5942, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5945, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5947, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5948, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5949, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5949, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5949, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Training time: 1.20 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, torch_training_duration = lr_methods.fit(model, optimizer, criterion, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display `training` and `validation` losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the losses\n",
    "lr_methods.display_losses(training=train_losses, testing=test_losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display `training`, `validation` and `test` accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 69.97%\n",
      "Validation accuracy: 69.58%\n",
      "Test accuracy: 70.16%\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = df_test.drop(columns=[\"label\"]), df_test[\"label\"]\n",
    "\n",
    "lr_methods.evaluate(type='Training', model=model, X=X_train, y=y_train)\n",
    "lr_methods.evaluate(type='Validation', model=model, X=X_val, y=y_val)\n",
    "lr_methods.evaluate(type='Test', model=model, X=X_test, y=y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning - Cross-validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first define some initial hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss\n",
    "optimizer = torch.optim.SGD\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.5\n",
    "epochs = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step, we use the [skorch](https://skorch.readthedocs.io/en/stable/) library to wrap the PyTorch model into a scikit-learn compatible model. This allows us to use the scikit-learn tools for hyperparameters tuning.\n",
    "\n",
    "We first define a `skorch` wrapper for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "skorch_net: NeuralNetClassifier = NeuralNetClassifier(\n",
    "    module=LogisticRegression,\n",
    "    module__input_dim=8,\n",
    "    module__nb_classes=1,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    optimizer__lr=learning_rate,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    max_epochs=epochs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different steps of the cross-validation here are the following:\n",
    "* We create a dictionary of hyperparameters to tune. For each hyperparameter, we define a list of values to try.\n",
    "\n",
    "* We create a `GridSearchCV` object, which will try all possible combinations of hyperparameters when fitting.\n",
    "\n",
    "* We convert the training data to `torch` tensors.\n",
    "\n",
    "* We fit the `GridSearchCV` object on the training set. This will train a model for each combination of hyperparameters, and keep the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV 1/2] END optimizer__lr=0.01, optimizer__weight_decay=1.0;, score=0.695 total time=   3.4s\n",
      "[CV 2/2] END optimizer__lr=0.01, optimizer__weight_decay=1.0;, score=0.532 total time=   3.2s\n",
      "[CV 1/2] END optimizer__lr=0.01, optimizer__weight_decay=0.7;, score=0.695 total time=   3.3s\n",
      "[CV 2/2] END optimizer__lr=0.01, optimizer__weight_decay=0.7;, score=0.541 total time=   3.3s\n",
      "[CV 1/2] END optimizer__lr=0.01, optimizer__weight_decay=0.5;, score=0.696 total time=   3.6s\n",
      "[CV 2/2] END optimizer__lr=0.01, optimizer__weight_decay=0.5;, score=0.549 total time=   3.4s\n",
      "[CV 1/2] END optimizer__lr=0.005, optimizer__weight_decay=1.0;, score=0.695 total time=   3.3s\n",
      "[CV 2/2] END optimizer__lr=0.005, optimizer__weight_decay=1.0;, score=0.610 total time=   3.3s\n",
      "[CV 1/2] END optimizer__lr=0.005, optimizer__weight_decay=0.7;, score=0.695 total time=   3.3s\n",
      "[CV 2/2] END optimizer__lr=0.005, optimizer__weight_decay=0.7;, score=0.617 total time=   3.3s\n",
      "[CV 1/2] END optimizer__lr=0.005, optimizer__weight_decay=0.5;, score=0.695 total time=   3.3s\n",
      "[CV 2/2] END optimizer__lr=0.005, optimizer__weight_decay=0.5;, score=0.625 total time=   3.3s\n",
      "[CV 1/2] END optimizer__lr=0.001, optimizer__weight_decay=1.0;, score=0.696 total time=   3.3s\n",
      "[CV 2/2] END optimizer__lr=0.001, optimizer__weight_decay=1.0;, score=0.695 total time=   3.3s\n",
      "[CV 1/2] END optimizer__lr=0.001, optimizer__weight_decay=0.7;, score=0.696 total time=   3.3s\n",
      "[CV 2/2] END optimizer__lr=0.001, optimizer__weight_decay=0.7;, score=0.695 total time=   3.3s\n",
      "[CV 1/2] END optimizer__lr=0.001, optimizer__weight_decay=0.5;, score=0.696 total time=   3.3s\n",
      "[CV 2/2] END optimizer__lr=0.001, optimizer__weight_decay=0.5;, score=0.697 total time=   3.3s\n"
     ]
    }
   ],
   "source": [
    "# Prevent skorch logs from being printed\n",
    "skorch_net.set_params(train_split=False, verbose=0)\n",
    "\n",
    "# Define the parameters to be tested in the grid search\n",
    "params: dict[str, list[float]] = {\n",
    "    'optimizer__lr': [0.01, 0.005, 0.001],\n",
    "    'optimizer__weight_decay': [1.0, 0.7, 0.5]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search (scikit-learn) object\n",
    "grid_search = GridSearchCV(skorch_net, params, refit=False, cv=2, scoring='accuracy', verbose=3, error_score='raise')\n",
    "\n",
    "# Convert the training data to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values).float()\n",
    "y_train_tensor = torch.tensor(y_train.values).float().unsqueeze(1)\n",
    "\n",
    "# Perform the grid search on the training data through the fitting method of the skorch model.\n",
    "history = grid_search.fit(X_train_tensor, y_train_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the best score and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.697\n",
      "Best parameters: {'optimizer__lr': 0.001, 'optimizer__weight_decay': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: {:.3f}\".format(history.best_score_))\n",
    "print(\"Best parameters: {}\".format(history.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(1 point)** Look at the weights of your classifier. Which features seems to play most for both classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0340, -0.0496, -0.0079, -0.0070, -0.0229,  0.1296, -0.1532,  0.0086],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Positive class\n",
      "\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1296, 0.0086], grad_fn=<TopkBackward0>),\n",
      "indices=tensor([5, 7]))\n",
      "\n",
      "Negative class\n",
      "\n",
      "torch.return_types.topk(\n",
      "values=tensor([-0.1532, -0.0496], grad_fn=<TopkBackward0>),\n",
      "indices=tensor([6, 1]))\n"
     ]
    }
   ],
   "source": [
    "# Print the 2 biggest weights of the features for both classes.\n",
    "print(model.linear.weight[0])\n",
    "\n",
    "print(\"\\nPositive class\\n\")\n",
    "print(model.linear.weight[0].topk(2))\n",
    "\n",
    "\n",
    "print(\"\\nNegative class\\n\")\n",
    "print(model.linear.weight[0].topk(2, largest=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the positive class, the number of positive words and the presence of exclamation marks are the most important features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the negative class, the number of negative words and the number of first person pronouns are the most important features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **\\[Bonus\\]** The parameter `weight_decay` of the [SGD optimizer](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) corresponds to the L2 penalty. Try playing with this value and explain how it influence the model's weights."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **weight_decay** parameter adds a L2 penalty (also known as ridge regularization) to the cost. It can reduce the impact of large coefficients and encourage the model to have smaller and more balanced coefficients, which can lead to better generalization performance and prevent overfitting.\n",
    "\n",
    "The strength of the L2 penalty is controlled by the lambda hyperparameter. Increasing the value of lambda increases the strength of the penalty and results in smaller coefficients, which can reduce overfitting but may also reduce the model's ability to capture complex relationships in the data.\n",
    "\n",
    "However, it is important to choose an appropriate value of lambda that balances the trade-off between bias and variance, as a too strong penalty can lead to underfitting and a too weak penalty can lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(1 point)** Take two wrongly classified samples in the test set and try explaining why the model was wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>first_pronouns</th>\n",
       "      <th>second_pronouns</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>log_word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>label</th>\n",
       "      <th>third_person</th>\n",
       "      <th>prediction</th>\n",
       "      <th>wrongly_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.897840</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.655992</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.247024</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.752573</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.304065</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.897840</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.727388</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.356586</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.929589</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8714 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no  first_pronouns  second_pronouns  exclamation  log_word_count  \\\n",
       "4       0               2                2            1        4.897840   \n",
       "6       1               2                3            0        5.655992   \n",
       "11      0               6                0            0        5.247024   \n",
       "46      1               7                2            1        5.752573   \n",
       "63      0               0                0            0        4.304065   \n",
       "...    ..             ...              ...          ...             ...   \n",
       "24993   0               1                1            1        4.897840   \n",
       "24996   0               4                2            1        4.727388   \n",
       "24997   0               2                0            0        5.356586   \n",
       "24998   1               7                2            1        5.929589   \n",
       "24999   0               1                0            0        4.852030   \n",
       "\n",
       "       positive  negative  label  third_person  prediction  wrongly_classified  \n",
       "4            12         2      0             4           1                True  \n",
       "6            19        11      0             5           1                True  \n",
       "11           11         3      0             6           1                True  \n",
       "46           15         4      0             6           1                True  \n",
       "63            6         1      0             7           1                True  \n",
       "...         ...       ...    ...           ...         ...                 ...  \n",
       "24993         6         4      1             1           0                True  \n",
       "24996         7         3      1             1           0                True  \n",
       "24997        11         5      1             4           0                True  \n",
       "24998        13        12      1             5           0                True  \n",
       "24999         7         7      1             2           0                True  \n",
       "\n",
       "[8714 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_copy = df_test.copy()\n",
    "\n",
    "df_test_copy[\"prediction\"] = model(torch.tensor(X_test.values).float()).detach().numpy()\n",
    "df_test_copy[\"prediction\"] = df_test_copy[\"prediction\"].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "df_test_copy[\"wrongly_classified\"] = df_test_copy[\"prediction\"] != df_test_copy[\"label\"]\n",
    "df_test_copy[df_test_copy[\"wrongly_classified\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First wrongly classified sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>first_pronouns</th>\n",
       "      <th>second_pronouns</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>log_word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>label</th>\n",
       "      <th>third_person</th>\n",
       "      <th>prediction</th>\n",
       "      <th>wrongly_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.89784</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no  first_pronouns  second_pronouns  exclamation  log_word_count  positive  \\\n",
       "4   0               2                2            1         4.89784        12   \n",
       "\n",
       "   negative  label  third_person  prediction  wrongly_classified  \n",
       "4         2      0             4           1                True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First wrong prediction\n",
    "df_test_copy[df_test_copy[\"wrongly_classified\"]].head(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicted a positive label, but the true label is negative.\n",
    "\n",
    "We can see that the number of positive words is higher than the number of negative words.\n",
    "\n",
    "Also the presence of exclamation marks is a strong indicator of a positive label, as we saw in the previous part.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second wrongly classified sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>first_pronouns</th>\n",
       "      <th>second_pronouns</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>log_word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>label</th>\n",
       "      <th>third_person</th>\n",
       "      <th>prediction</th>\n",
       "      <th>wrongly_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.929589</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       no  first_pronouns  second_pronouns  exclamation  log_word_count  \\\n",
       "24998   1               7                2            1        5.929589   \n",
       "\n",
       "       positive  negative  label  third_person  prediction  wrongly_classified  \n",
       "24998        13        12      1             5           0                True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second wrong prediction\n",
    "df_test_copy[df_test_copy[\"wrongly_classified\"]][-2:-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the model predicted a negative label, but the true label is positive. \n",
    "\n",
    "The number of positive words is higher than the negative one. But as we can see, the presence of a no in the sentence may influence our model.\n",
    "\n",
    "The number of first pronouns is high, we saw that it could be a factor of influence for negative class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **\\[Bonus\\]** Train logistic regression classifier using the [scikit-learn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). How does it compare with the PyTorch version?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.08 seconds\n"
     ]
    }
   ],
   "source": [
    "# Add a L2 penalty to the logistic regression classifier\n",
    "model: SKLogisticRegression = scikit_learn_lr.model(penalty='l2', C=0.001)\n",
    "\n",
    "# Train the model on the training set\n",
    "sk_training_duration = scikit_learn_lr.fit(model, X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 69.91%\n",
      "Validation accuracy: 69.68%\n",
      "Test accuracy: 70.19%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "_ = scikit_learn_lr.evaluate(model, X_train, y_train, type=\"Training\")\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "scikit_learn_lr.evaluate(model, X_val, y_val, type=\"Validation\")\n",
    "\n",
    "# Split the test_df into X_test and y_test\n",
    "_ = X_test = df_test.drop(columns=[\"label\"])\n",
    "_ = y_test = df_test[\"label\"]\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "_ = scikit_learn_lr.evaluate(model, X_test, y_test, type=\"Test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the sklearn logistic regression classifier is comparable to the accuracy of the PyTorch model, as both models have an accuracy approximately the same accuracy on all three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn model performed 15.15 times faster than the PyTorch model.\n"
     ]
    }
   ],
   "source": [
    "# Compare the training duration of the PyTorch and Scikit-Learn models as ratio\n",
    "ratio: float = torch_training_duration / sk_training_duration\n",
    "print(f\"The scikit-learn model performed {ratio:.2f} times faster than the PyTorch model.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting observation is that the sklearn model has a much shorter training duration shorter than the PyTorch model, which can be an important factor when training a model on a large dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
