{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [FastText library](https://fasttext.cc/docs/en/support.html) to train and test a classifier.\n",
    "\n",
    "Go through the following steps.\n",
    "1. (2 points) Turn the dataset into a dataset compatible with Fastext (see the _Tips on using FastText_ section a bit lower).\n",
    "   * For pretreatment, only apply lower casing and punctuation removal.\n",
    "2. (2 points) Train a FastText classifier with default parameters on the training data, and evaluate it on the test data using accuracy.\n",
    "3. (2 points) Use the [hyperparameters search functionality](https://fasttext.cc/docs/en/autotune.html) of FastText and repeat step 2.\n",
    "   * To do so, you'll need to [split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) your training set into a training and a validation set.\n",
    "   * Let the model search for 5 minutes (it's the default search time).\n",
    "   * Don't forget to shuffle (and stratify) your splits. The dataset has its entry ordered by label (0s first, then 1s). Feeding the classifier one class and then the second can mess with its performances.\n",
    "4. (1 points) Look at the differences between the default model and the attributes found with hyperparameters search. How do the two models differ?\n",
    "   * Only refer to the attributes you think are interesting.\n",
    "   * See the _Tips on using FastText_ (just below) for help.\n",
    "5. (1 point) Using the tuned model, take at least 2 wrongly classified examples from the test set, and try explaining why the model failed.\n",
    "6. (Bonus point) Why is it likely that the attributes `minn` and `maxn` are at 0 after an hyperparameter search on our data?\n",
    "   * Hint: on what language are we working?\n",
    "\n",
    "### Tips on using FastText\n",
    "\n",
    "FastText is not exactly documented in details, so you might run into a few problems. The following tips can be useful.\n",
    "\n",
    "#### Training file format\n",
    "\n",
    "Training a FastText classifier takes a text file as input. Every line corresponds to a sample and must have the following format\n",
    "```\n",
    "__label__<your_label> <corresponding text>\n",
    "```\n",
    "For example, in our case a line should look like this.\n",
    "```\n",
    "__label__positive you know robin williams god bless him is constantly...\n",
    "```\n",
    "Also, the data are presented `positive` first and then `negative`. To avoid having a strong model bias toward `negative`, **shuffle your data before training**.\n",
    "\n",
    "#### Attributes\n",
    "\n",
    "You can check a model's attributes as they are listed on the [cheatsheet](https://fasttext.cc/docs/en/options.html). Also, if you have a well configure IDE or use Jupyter Lab, tab is your friend.\n",
    "\n",
    "#### Random seed\n",
    "\n",
    "To my knowledge, there is no way to set the random seed for FastText. It uses C++ code in the back, so using `random.seed()` won't help. For every other model you will use in these projects, please set the random seed to make your results reproductible.\n",
    "\n",
    "#### Data split\n",
    "\n",
    "Do not use the test set for hyperparameters search. Extract a validation set from the training data for that purpose. The test set is only made for comparing final models (see [data leakage](https://en.wikipedia.org/wiki/Leakage_%28machine_learning%29))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois.soulier/miniconda/envs/SCIA/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "from scripts.sentiment_analysis import fast_text_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Load dataset as a `Pandas` dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/francois.soulier/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ca9e99139c4e40840b38934532d4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('imdb')\n",
    "df: pd.DataFrame = dataset['train'].to_pandas()\n",
    "\n",
    "# Display the first 5 rows of the training dataset\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset conversion to the FastText format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__negative i rented i am curiousyellow ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__negative i am curious yellow is a ris...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__negative if only to avoid making this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__negative this film was probably inspi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__negative oh brotherafter hearing abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  __label__negative i rented i am curiousyellow ...      0\n",
       "1  __label__negative i am curious yellow is a ris...      0\n",
       "2  __label__negative if only to avoid making this...      0\n",
       "3  __label__negative this film was probably inspi...      0\n",
       "4  __label__negative oh brotherafter hearing abou...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply pretreatment to the text\n",
    "df['text'] = df['text'].apply(fast_text_utils.preprocess_text)\n",
    "\n",
    "# Convert the data to FastText format\n",
    "fast_text_utils.to_fast_text_format(df=df, label_column_name='label', texts_column_name='text')\n",
    "\n",
    "# Keep only the text column\n",
    "# train_df = train_df[['text']]\n",
    "\n",
    "# Display some rows of the newly formatted data\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train, validation and test sets with `scikit-learn`. Also, we set a high random state to shuffle the datasets well enough in order to keep consistant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df[['text']], test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PATH = './output/train.txt'\n",
    "VALIDATION_PATH = './output/val.txt'\n",
    "TEST_PATH = './output/test.txt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the different datasets to their respective paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "\n",
    "# Write the data to the output files\n",
    "fast_text_utils.save_to_file(df=train_df, file_name=TRAINING_PATH)\n",
    "fast_text_utils.save_to_file(df=val_df, file_name=VALIDATION_PATH)\n",
    "fast_text_utils.save_to_file(df=test_df, file_name=TEST_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `FastText` classifier with the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  95575\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 2833902 lr:  0.000000 avg.loss:  0.475094 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "ft_classifier_default = fasttext.train_supervised(TRAINING_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the classifier on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 5000\n",
      "Precision: 85.34%\n",
      "Recall: 0.8534\n"
     ]
    }
   ],
   "source": [
    "results = ft_classifier_default.test(TEST_PATH)\n",
    "fast_text_utils.display_results(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new `FastText` classifier, feeding it with the validation dataset this time. We also specify the training duration (5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:   30 Best score:  0.894250 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 3M words\n",
      "Number of words:  95575\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  760747 lr:  0.000000 avg.loss:  0.073967 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "ft_classifier_tuned = fasttext.train_supervised(input=TRAINING_PATH, autotuneValidationFile=VALIDATION_PATH, autotuneDuration=5 * 60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the newly autotuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 5000\n",
      "Precision: 89.56%\n",
      "Recall: 0.8956\n"
     ]
    }
   ],
   "source": [
    "results = ft_classifier_tuned.test(TEST_PATH)\n",
    "fast_text_utils.display_results(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a precision and recall of ~4% higher on the `tuned` model than the `default` model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Default model attributes -- \n",
      "dim: 100\n",
      "ws: 5\n",
      "epoch: 5\n",
      "lr: 0.1\n",
      "wordNgrams: 1\n",
      "loss: loss_name.softmax\n",
      "lrUpdateRate: 100\n",
      "bucket: 0\n",
      "\n",
      "-- Tuned model attributes --\n",
      "dim: 10\n",
      "ws: 5\n",
      "epoch: 77\n",
      "lr: 0.5467089873546624\n",
      "wordNgrams: 5\n",
      "loss: loss_name.softmax\n",
      "lrUpdateRate: 100\n",
      "bucket: 1223063\n"
     ]
    }
   ],
   "source": [
    "# Define a selection of relevant hyperparameters to observe\n",
    "attributes_list: list[str] = ['dim', 'ws', 'epoch', 'lr', 'wordNgrams', 'loss', 'lrUpdateRate', 'bucket']\n",
    "\n",
    "# Display the default model attributes\n",
    "print('-- Default model attributes -- ')\n",
    "fast_text_utils.display_model_attributes(model=ft_classifier_default, parameters=attributes_list)\n",
    "\n",
    "print()\n",
    "\n",
    "# Display the tuned model attributes\n",
    "print('-- Tuned model attributes --')\n",
    "fast_text_utils.display_model_attributes(model=ft_classifier_tuned, parameters=attributes_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we can observe that the context window, the loss, the learning rate update rate, are constant between the two models.\n",
    "\n",
    "Then, we can compare the hyperparameters differences of the two models exhaustively:\n",
    "* `dim` (size of word vectors) - The tuning reduced the dimensionality of the vectors almost by a 10 factor (100 vs 10). We can assume that the model input is less complex and thus less prone to overfitting.\n",
    "\n",
    "* `epoch` (number of epochs) - Here again, the number epochs (iterations) much higher in the default model (5 vs 77). Logically, the more the model is trained, the more the accuracy should increase. However, the model is more prone to overfitting, but the tuning process helped to reduce this effect by selecting the best hyperparameter value.\n",
    "\n",
    "* `lr` (learning rate) - The tuning process almost multiplied the learning rate by 5 (0.1 vs ~0.55). This goes in the same direction as the previous point, as the learning rate should (generally) vary in regard to the number of epochs. This proves that the default model was undertrained.\n",
    "\n",
    "* `wordNgrams` (max length of word ngram) - The word ngrams increased from 1 to 5. We can assume that this choice was made to prevent the model from overfitting, as the model is now able to take into account the context of the word. Therefore, the model specializes less on the training data and is more generalizable.\n",
    "\n",
    "* `bucket` (number of buckets) - Comparing the number of buckets in the two models (0 vs 1223063), we can make the hypothesis that using a certain amount of buckets is more efficient than using none. As the model takes into account the context of a word, the number of buckets becomes This is probably due to the fact that the model is now able to take into account the context of the word, and thus the number of buckets is more relevant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example:  __label__negative i did not like the idea of the female turtle at all since 1987 we knew the tmnt to be four brothers with their teacher splinter and their enemies and each one of the four brothers are named after the great artists name like leonardo  michelangleo raphel and donatello so venus here doesnt have any meaning or playing any important part and i believe that the old tmnt series was much more better than that new one which contains venus as a female turtle will not add any action to the story we like the story of the tmnt we knew in 1987 to have new enemies in every part is a good point to have some action but to have a female turtle is a very weak point to have some action we wish to see more new of tmnt series but just as the same characters we knew in 1987 without that female turtle\n",
      "Prediction:  __label__positive\n",
      "Confidence: 65.09%\n",
      "Ground truth:  __label__negative\n",
      "\n",
      "Example:  __label__negative i am not so much like love sick as i image finally the film express sexual relationship of alex kik sandu their triangle love were full of intenseness frustration and jealous at last alex waked up and realized that they would not have result and futureending up was sadbr br the director tudor giurgiu was in amc theatre on sunday 1200pm on 081006 with us watched the movie together after the movie he told the audiences that the purposed to create this film which was to express the sexual relationships of romanian were kind of complicatebr br on my point of view sexual life is always complicated in everywhere i dont feel any particular impression and effect from the movie the love proceeding of alex and kiki and kiki and her brother sandu were kind of next door neighborhood storybr br the two main reasons i dont like this movie are firstly the film didnt told us how they started to fall in love sounds like after alex moved into the building which kiki was living then two girls are fall in love it doesnt make sense at all how a girl would fall in love with another girl instead of a man too much fragments you need to image and connect those stories by your mind secondly the whole film didnt have a scene of alex and kiks sexual intercourse that s what i was waiting for however it still had some parts were deserved to recommend the ear piercing  part was kind of interesting alex was willing to suffer the pain of ear piercing to appreciate kiks love that was a touching scene which gave you a little idea of their love also the scene of they were lying in the soccer field the conversation express their loves were truthful and passionate\n",
      "Prediction:  __label__positive\n",
      "Confidence: 75.77%\n",
      "Ground truth:  __label__negative\n"
     ]
    }
   ],
   "source": [
    "examples: list[tuple] = []\n",
    "\n",
    "# Select two examples that were misclassified\n",
    "for i in range(df.shape[0]):\n",
    "    example = df['text'].iloc[i]\n",
    "    ground_truth = '__label__' + ('positive' if df['label'].iloc[i] else 'negative')\n",
    "    prediction = ft_classifier_tuned.predict(example)\n",
    "\n",
    "    if prediction[0][0] != ground_truth:\n",
    "        examples.append((example, prediction[0][0], prediction[1][0], ground_truth))\n",
    "    \n",
    "    if len(examples) == 2:\n",
    "        break\n",
    "\n",
    "# Display the examples\n",
    "for example in examples:\n",
    "    print()\n",
    "    print('Example: ', example[0])\n",
    "    print('Prediction: ', example[1])\n",
    "    print(f'Confidence: {example[2] * 100:.2f}%')\n",
    "    print('Ground truth: ', example[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First example\n",
    "\n",
    "The text is very descriptive and does not brightly highlight real sentiments. Here we could assume the classification has been on the movie synopsis (which represents the most part of the text), and not really on the review part.\n",
    "\n",
    "* Second example\n",
    "\n",
    "This example has been classified as `positive`, whereas it is actually `negative`. The text represents a detailed description, which contains a lot of positive words in the describing process. However, the lack context consideration is at stake here, because our (human) sentiment classification would be here base on adjacent words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus question\n",
    "\n",
    "### Why is it likely that the attributes minn and maxn are at 0 after a hyperparameter search on our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Default model attributes -- \n",
      "minn: 0\n",
      "maxn: 0\n",
      "-- Tuned model attributes --\n",
      "minn: 2\n",
      "maxn: 5\n"
     ]
    }
   ],
   "source": [
    "parameters: list[str] = ['minn', 'maxn']\n",
    "\n",
    "# Display the default model attributes\n",
    "print('-- Default model attributes -- ')\n",
    "fast_text_utils.display_model_attributes(model=ft_classifier_default, parameters=parameters)\n",
    "# Display the tuned model attributes\n",
    "print('-- Tuned model attributes --')\n",
    "fast_text_utils.display_model_attributes(model=ft_classifier_tuned, parameters=parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are here processing English texts. Thus, as we want to take the context of a word into consideration, we would rather use the `wordNgrams` hyperparameter. The `minn` and `maxn` hyperparameters are used to caption characters contexts, which is not very relevant in the case of English.\n",
    "\n",
    "However, we have here the contrary situation, as the `minn` and `maxn` hyperparameters are not set to 0 after hyperparameter tuning. This is probably due to the fact that the model is now able to take into account the context of the word, and thus the number of buckets is more relevant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
